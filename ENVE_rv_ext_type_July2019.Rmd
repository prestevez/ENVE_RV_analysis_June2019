---
title: "Extortion concentration patterns: Analysis by type and event dependence, version 0.3"
author: "Patricio R. Estevez Soto"
email: "patricio.estevez.14@ucl.ac.uk"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  md_document:
    variant: "markdown"
pandoc_args: "--smart"
params:
    test:
        label: "Testing (for development)"
        value: FALSE
references:
- id: Estevez-Soto2019
  type: article-journal
  author:
  - family: Estévez-Soto
    given: Patricio R
  - family: Johnson
    given: Shane D
  - family: Tilley
    given: Nick
  issued:
  - year: '2018'
  title: Are repeatedly extorted businesses different? A multilevel hurdle model of extortion victimization
  container-title: Manuscript under review (Submitted Sep. 27, 2018)
- id: Estevez-Soto2019a
  type: article-journal
  author:
  - family: Estévez-Soto
    given: Patricio R
  issued:
  - year: '2019'
  title: |
   Determinants of extortion compliance: Empirical evidence from a victimisation survey
  container-title: Manuscript in preparation (Submitted June 26, 2019)
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      comment="",
                      cache=TRUE,
                      dev=c("png", "CairoPDF"),
                      error=TRUE,
                      fig.width=6, fig.height=5)
options(knitr.kable.NA = '--')
```

This script continues the analysis of the patterns of extortion concentration based on the findings from two previous studies. Using data form a commercial victimisation survey in Mexico, the first study [@Estevez-Soto2019] examined whether the predictors of extortion prevalence were the same as the predictors of extortion concentration using a multilevel negative binomial-logit hurdle model. The study found that the risk factors for extortion prevalence were not the same as those fuelling extortion concentration, possibly due to an unmeasured process of event dependence.

As the likelihood of repeat victimisation is thought to be influenced by how victims respond to a previous event, the second study [@Estevez-Soto2019a] examined the predictors of extortion compliance. Specifically, it sought to answer why most incidents of extortion in Mexico are not complied with. The main hypothesis was that the communication channel used to convey extortion threats was very important in determining compliance, as threats conveyed using lean media (remote extortion) would be less believable than those conveyed using rich media (in-person extortion). The findings suggested that compliance varied widely between remote and in-person extortion, which in turn suggested that extortion analyses should consider these types as different offence classes: the concentration patterns for remote and in-person extortion may be fuelled by different mechanisms.

Thus, Part 1 of this study aims to study the concentration patterns of remote and in-person extortion separately. It will estimate models of incidence (count), prevalence (logit) and concentration (truncated count) on remote and inperson extortion only (no need to estimate extincs models). As there are no repeat cobro de piso incidents, only prevalence models will be estimated for this category. Previous iterations have shown that multilevel specifications may not be appropriate, so those results will be heeded. Also, previous iterations showed that a better functional form for bribes is log(bribes) or poly(bribes), thus these specifications will be used (though appropriate comparisons with bribes will be made).

Part 2, in contrast, will incorporate the temporal dimension to the analysis by creating a synthetic panel based on the month the incident was reported to have occurred. The temporal dimension will be used to calculate the time-course of repeat incidents (a histogram of the times between repetitions), as well as to model the probability of a future event, based on measurements from a previous period. As results from Part 1 illustrate that incidence models are not appropriate (the coefficients for prevalence are distinct from those of concentration), this study will only fit models for prevalence and concentration. The models will not include variables that are not significant, based on results from previous iterations.

Standard packages used to deal with multilevel count data (e.g. `glmmTMB`, `glmmADMB` and `lme4`) do not have truncated distributions (other than truncated-at-zero distributions for hurdle models). In contrast, the `GAMLSS` package allows specifying right-, left-, and interval-truncated count distributions for virtually any situation. However, the package does not allow multilevel specifications (i.e. random intercepts). There is a `gamlssNP` function that allows specifying random intercepts using Gaussian Mixtures, but I've discovered a critical bug in the software that inadvertently drops terms from the specified formula.

Previous iterations of this analysis suggest two things: one, the multilevel specification is important (as random intercepts were deemed to be significant to the models), and two, the benefits of using the 'correct' distribution using left-, and interval-truncation are negligible. Single-level models using the un-truncated distributional assumptions (and the truncated data) showed no substantive differences in effect sizes nor in statistical inference. Furthermore, the `gamlss` estimates appear to be far more unreliable than those using the standard packages.

Previous iterations of the analysis suggest that glmmTMB is notoriously unreliable to estimate truncated models, though untruncated count models are estimated correctly. Thus, glmmADMB will be preferred for untruncated models.

As a sanity check, I will also, repeat main model from study 1, just to make sure all issues are resolved. The main issue is to do an LR test between MTP and MTNB models for uncapped extortions (fit using glmmADMB).


The script proceeds as follows: In the next section I set-up the R workspace, load and install the necessary packages and set up other options. This is followed by data input and wrangling. Then the revisions to the compliance study [@Estevez-Soto2019a] are conducted, and this is followed by the analyses for this study.

# Set up

To ensure reproducibility and aid in debugging, we first start setting up options and printing the information about the R session.

```{r session, cache=FALSE}
starttime <- proc.time()
date()
sessionInfo()
set.seed(42)
options(scipen=0)

```

Next we load the packages that will be used in the analysis. The installation of these packages should have already been done before. Additionally, we'll import some functions that are required, without importing the entire packages.

```{r packages}
library(victim)
library(tidyverse)
library(downloader)
library(sandwich)
library(lmtest)
library(magrittr)
library(glmmTMB)
library(lazyeval)
library(glmmADMB)
step <- stats::step
library(arsenal)
library(texreg)
library(bbmle)
library(gridExtra)



read.dbf <- foreign::read.dbf
kable <- knitr::kable
melt <- reshape2::melt
select <- dplyr::select
Anova <- car::Anova
ks.test <- dgof::ks.test

sessionInfo()

# Create csv dir for model results
dir.create("coef_results")

```

Next we load some custom functions. Ideally these should be in a separate stand-alone package, but I have not had the time to create such package.

```{r functions}

mylog <- function(x, center = FALSE){
    if(min(x) <= 0) {tlog <- log1p}
    else {tlog <- log}

    logx <- tlog(x)

    if(isTRUE(center))
    {
        logx <- logx - tlog(mean(x))
    }

    if(is.numeric(center)){
        logx <- logx - tlog(center)
    }

    return(logx)

}

mkbin <- function(x,n = 0) ifelse(x > n, 1, 0)

capadjust <- function(x, y, K = 0) x/(K-y)

# Unconditional truncated means

tnb_mean <- function(mu, alpha) mu/(1-(1+alpha*mu)^(-1/alpha))
tp_mean <- function(mu) mu/(1-exp(-mu))


countsummary <- function(model){
    print(summary(model))
    print(confint(model))
    sgm <- sigma(model)

    if(length(sgm) == 0){
        sgm <- model$alpha
    }
    cat("\n\nSigma: \n")
    print(1/sgm)
    cat("\nLog-likelihood: \n")
    print(logLik(model))
    cat("\n")
    print(car::Anova(model))
    print(lrtest(model))
}

compare_nested <- function(...) {
    print(AICtab(...))
    print(lrtest(...))
}

## write a function to calculate the half-life
half_life <- function(model, hl = 0.50, ci = TRUE, ...){
    half_life <- log(hl)/coef(model)[2]
    results <- list(HL = half_life)
    if(ci){
        hl_ci <- log(hl)/confint(model, ...)[2,]
        results$CI <- hl_ci
    }
    return(results)
}

### Function to extract model coefficients to csv
## Should work for glmmTMB and glmmADMB models

coef_csv <- function(model, dir = "coef_results/"){
    if(class(model) == "glmmTMB"){
        coefs1 <- fixef(model)$cond
        ses1 <- sqrt(diag(vcov(model)$cond))
    } else{
        coefs1 <- coef(model)
        ses1 <- sqrt(diag(vcov(model)))
    }
    ncoefs1 <- length(coefs1)
    ses1 <- ses1[1:ncoefs1]

    confints1 <- confint(model)

    confints1 <- confints1[1:ncoefs1,1:2]

    mat <- cbind(coefs1,ses1,confints1)
    colnames(mat) <- c("Estimate", "SE", "CI_low", "CI_high")

    mname <- deparse(substitute(model))

    filename <- paste0(dir, mname, ".csv")

    write.csv(mat, file = filename)

    message("\nFile: '", filename, "' successfully writen!\n")

}

```

# Data input and processing

We first load and arrange the area and victim level data.

As the script is designed to be run remotely, when working locally during development, testing data needs to be downloaded from github. To download the testing data, the script uses an Rmarkdown parameter (`params$test`). The parameter is set to `FALSE` by default, so that it runs seamlessly using the `render` command when running in the remote research settings. For running correctly in a testing setting, the parameter must be given a `TRUE` value when running the knit command (`rmarkdown::render('ENVE_rv_ext_type.Rmd', params = list(test = TRUE))`). When using `knitr`, no parameter is passed, so the following gives an error. This is expected behaviour.

```{r testing}
#params <- list(test = TRUE)
if(params$test){
    download("https://raw.githubusercontent.com/prestevez/datahouse/master/enve2014cuest_ciega_2014.dbf",
                      destfile = "enve2014cuest_ciega_2014.dbf", mode = "wb")
    download("https://raw.githubusercontent.com/prestevez/datahouse/master/enve2014delitos_ciega_2014.dbf",
                 destfile = "enve2014delitos_ciega_2014.dbf", mode = "wb")
}

```

Next we explore what files are available in the working directory.

```{r files}

list.files()

```

Next we input the additional data needed for the analysis currently saved in Github.

```{r GH-data}

cat_entidades <- read.csv("https://raw.githubusercontent.com/prestevez/datahouse/master/cat_entidades.csv", head=TRUE)
state_level_data <- read.csv("https://raw.githubusercontent.com/prestevez/datahouse/master/state_level_data_2013.csv", header=TRUE)
state_level_data <- merge(state_level_data,
                          cat_entidades, by="CVE_ENT", all.x=TRUE)
scode <- read.csv("https://raw.githubusercontent.com/prestevez/datahouse/master/secode.csv", head=TRUE)
scode$Code <- scode$Code*10000


```

Now we are ready to input the victim-level data.

```{r victim-level-import}
enve_all <- read.dbf("enve2014cuest_ciega_2014.dbf")

```

To prepare the data for analysis we select only the variables that are used in the analysis.

```{r victim-level-processing}

enve_test <- data.frame(extortions=as.integer(as.character(enve_all$P26_10)))

enve_test$extortion_victim <- enve_all$P25_10
enve_test$extortions[enve_test$extortion_victim == 2] <- 0
summary(enve_test$extortions)
table(enve_test$extortions)

enve_test$extortions[is.na(enve_test$extortions)] <- 0

summary(enve_test$extortions)
table(enve_test$extortions)


enve_test$rep_extortion_victim <- mkbin(enve_test$extortions, 1)
#enve_test$rep_extortion_victim <- factor(enve_test$extortions)
#levels(enve_test$rep_extortion_victim) <- c(0, 0,
#                    rep(1, length(levels(enve_test$rep_extortion_victim)) - 2))

table(enve_test$rep_extortion_victim)

enve_test$rep_extortions <- enve_test$extortions
enve_test$rep_extortions[enve_test$rep_extortions > 0] <- enve_test$rep_extortions[enve_test$rep_extortions > 0] - 1

summary(enve_test$rep_extortions)
table(enve_test$rep_extortions)


enve_test$CVE_UNICA <- as.integer(as.character(enve_all$ID_CONSECU))

enve_test$bribes <- as.integer(as.character(enve_all$P33))
summary(enve_test$bribes)

# 4 bribe cats
enve_test$bribe1 <- enve_all$P29_1
enve_test$bribe2 <- enve_all$P30_1
enve_test$bribe3 <- enve_all$P31_1
enve_test$bribe4 <- enve_all$P32_1

enve_test$bribes[with(enve_test,
                        bribe1 == 2 &
                        bribe2 == 2 &
                        bribe3 == 2 &
                        bribe4 == 2)] <- 0

summary(enve_test$bribes)

enve_test$bribes[is.na(enve_test$bribes)] <- 0

enve_test$bribe_victim <- mkbin(enve_test$bribes, 0)

table(enve_test$bribe_victim)

enve_test$rep_bribe <- mkbin(enve_test$bribes, 1)

table(enve_test$rep_bribe)

enve_test$bribe_cats <- factor(enve_test$bribes)
levels(enve_test$bribe_cats) <- c(0, 1, 2, rep("3+",
                                            length(levels(enve_test$bribe_cats)) - 3))
summary(enve_test$bribe_cats)

enve_test$CVE_ENT <- as.integer(as.character(enve_all$CVE_ENT))

enve_test$size <- enve_all$ID_ESTRATO
levels(enve_test$size) <- c("Large", "Medium", "Small", "Micro")

enve_test$sector <- enve_all$SECTOR_FIN

# subsector
enve_test$tempsub <- as.integer(as.character(enve_all$P1_1B))
enve_test$subsector <- cut(enve_test$tempsub, scode$Code, right=FALSE)
levels(enve_test$subsector) <- scode$Sector
enve_test$subsector <- droplevels(enve_test$subsector)
enve_test$subsector <- relevel(enve_test$subsector, ref="Retail")
levels(enve_test$subsector)

enve_test$subsector_safe <- enve_test$subsector

enve_test$subsector <- as.character(enve_test$subsector)

# Must remember to exclude utilities from analysis

enve_test$subsector[enve_test$subsector %in%
                      c("Mining",
                        "Construction")] <- "Other industry"

# Must remember to exclude Corporate from analysis

enve_test$subsector[enve_test$subsector %in%
                      c("Media",
                        "Maintenance",
                        "Other",
                        "Finance",
                        "Health",
                        "Leisure",
                        "Education",
                        "Prof. services",
                        "Real estate")] <- "Other serv."


enve_test$subsector <- as.factor(enve_test$subsector)
enve_test$subsector <- relevel(enve_test$subsector, ref="Retail")
levels(enve_test$subsector)
summary(enve_test$subsector)

enve_test$years <- 2013 - as.numeric(as.character(enve_all$P3))
summary(enve_test$years)

intyears <- classInt::classIntervals(enve_test$years, 5, style="quantile")
enve_test$yearsquant <- cut(enve_test$years, intyears$brks, right=TRUE,
                            include.lowest = TRUE)

enve_test <- merge(enve_test, state_level_data, by="CVE_ENT", all.x=TRUE)

length(enve_test$extortions[is.na(enve_test$extortions)])
length(enve_test$bribes[is.na(enve_test$bribes)])

## enve_test$extortions[is.na(enve_test$extortions)] <- 0
## enve_test$bribes[is.na(enve_test$bribes)] <- 0

summary(enve_test)

# Exclude Corporate and Utilitites

nrow(enve_test) # should be 28179


enve_test %>%
    filter(subsector != "Utilities") %>%
    filter(subsector != "Corporate") -> enve_test_2

enve_test_2$subsector <- droplevels(enve_test_2$subsector)

levels(enve_test_2$subsector)

enve_test_2$subsector_safe <- droplevels(enve_test_2$subsector_safe)
levels(enve_test_2$subsector_safe)

nrow(enve_test_2) # should be 28161

enve_test <- enve_test_2
nrow(enve_test)

summary(enve_test)
```

Next we import and prepare the incident-level data.

```{r incident-level}

enve_incidents_all <- read.dbf("enve2014delitos_ciega_2014.dbf")

# Selecting only those relevant for extortion (code 10)

enve_incidents_all$delito <- as.integer(as.character(enve_incidents_all$ID_DELITO))

enve_incidents <- enve_incidents_all[enve_incidents_all$delito == 10,]

# Selecting those relevant for our study

incident_df <- data.frame(CVE_UNICA=as.integer(as.character(enve_incidents$ID_CONSECU)))

incident_df$month <- as.numeric(as.character(enve_incidents$M1_1))

incident_df$delito <- enve_incidents$delito

incident_df$n_offenders <- enve_incidents$M1_8
summary(incident_df$n_offenders)

levels(incident_df$n_offenders) <- c(1:6, "DK/DA")
summary(incident_df$n_offenders)

incident_df$n_offenders_NA <-  incident_df$n_offenders
incident_df$n_offenders_NA[is.na(incident_df$n_offenders)] <- "DK/DA"
summary(incident_df$n_offenders_NA)

incident_df$n_offenders_old <- incident_df$n_offenders_NA
levels(incident_df$n_offenders_NA) <- c(1:3, "4+", "4+", "4+", "DK/DA")
summary(incident_df$n_offenders_NA)

incident_df$uk_n_offenders <- incident_df$n_offenders_NA

levels(incident_df$uk_n_offenders)[1:4] <- "known"

incident_df$n_offenders_num <- enve_incidents$M1_8
summary(incident_df$n_offenders_num)
levels(incident_df$n_offenders_num) <- c(1:6, 0)
summary(incident_df$n_offenders_num)
incident_df$n_offenders_num[is.na(incident_df$n_offenders_num)] <- 0
incident_df$n_offenders_num <- as.numeric(as.character(incident_df$n_offenders_num))
table(incident_df$n_offenders_num)

incident_df$n_offenders_num <- incident_df$n_offenders_num - 1


## Data imputation for missing variables?

incident_df$rel_offenders <- enve_incidents$M1_11
levels(incident_df$rel_offenders) <- c("Known", "Known",
                                       "Known", "Known",
                                       "Total stranger", "DK/DA")
incident_df$rel_offenders <- relevel(incident_df$rel_offenders, ref="Total stranger")
summary(incident_df$rel_offenders)

incident_df$rel_offenders_NA <- incident_df$rel_offenders
incident_df$rel_offenders_NA[is.na(incident_df$rel_offenders_NA)] <- "DK/DA"
summary(incident_df$rel_offenders_NA)

incident_df$had_weapon <- enve_incidents$M1_13
levels(incident_df$had_weapon) <- c("Yes", "No", "DK/DA")
incident_df$had_weapon <- relevel(incident_df$had_weapon, ref="No")
summary(incident_df$had_weapon)

incident_df$had_weapon_NA <- incident_df$had_weapon
incident_df$had_weapon_NA[is.na(incident_df$had_weapon_NA)] <- "DK/DA"
summary(incident_df$had_weapon_NA)

incident_df$extortion_type <- as.character(enve_incidents$M5_1)
incident_df$extortion_type <- as.factor(incident_df$extortion_type)
levels(incident_df$extortion_type) <- c("Remote", "Remote", "Street",
                                        "Premises", "Cobro de piso", "Other")
levels(incident_df$extortion_type)
summary(incident_df$extortion_type)

incident_df$extortion_type_bin <- as.character(enve_incidents$M5_1)
incident_df$extortion_type_bin <- as.factor(incident_df$extortion_type_bin)
levels(incident_df$extortion_type_bin) <- c("Remote", "Remote", "In person",
                                        "In person", "In person", "Other")
levels(incident_df$extortion_type_bin)
summary(incident_df$extortion_type_bin)

# Extortion bin w/o Cobro de piso
incident_df$extortion_type_wocp <- as.character(enve_incidents$M5_1)
incident_df$extortion_type_wocp <- as.factor(incident_df$extortion_type_wocp)
levels(incident_df$extortion_type_wocp) <- c("Remote", "Remote", "In person",
                                        "In person", "Other", "Other")
levels(incident_df$extortion_type_wocp)
summary(incident_df$extortion_type_wocp)


incident_df$complied <- enve_incidents$M5_3
levels(incident_df$complied) <-  c("Yes", "No", "DK/DA")
incident_df$complied <- relevel(incident_df$complied, ref="No")
summary(incident_df$complied)


incident_df$complied_bin <- enve_incidents$M5_3
levels(incident_df$complied_bin) <-  c("Yes", "No", NA)
incident_df$complied_bin <- relevel(incident_df$complied_bin, ref="No")
summary(incident_df$complied_bin)


incident_df$complied_bin_NA <- incident_df$complied_bin
incident_df$complied_bin_NA[is.na(incident_df$complied_bin_NA)] <- "No"
summary(incident_df$complied_bin_NA)

incident_df <- subset(incident_df, extortion_type != "Other")
incident_df$extortion_type <- droplevels(incident_df$extortion_type)

# Remember to subset out "other" obs from extortion_type_wocp
incident_df$extortion_type_bin <- droplevels(incident_df$extortion_type_bin)

summary(incident_df)
```

Next we merge both incident-level and victim-level tables.

```{r incident-victim-merge}
enve_incvic <- merge(incident_df, enve_test, by="CVE_UNICA")

nrow(enve_incvic)
nrow(incident_df)
```


# Revisions to compliance study

No revisions necessary.

Further data processing required for compliance study. Subsetting data excluding NA values.

```{r subset-no-NA}

## datasets with no NA values first.

nacols <- colnames(enve_incvic)[colSums(is.na(enve_incvic)) > 0]

nonacols <- names(enve_incvic)[!(names(enve_incvic) %in% nacols)]
nonacols
enve_incvic %>%
    select(nonacols) -> enve_nona

summary(enve_nona)
nrow(enve_nona)
nrow(enve_nona[complete.cases(enve_nona),])
nrow(enve_nona[complete.cases(enve_incvic),])

## Data structure

"number of incidents"
nrow(enve_nona)

"incidents per business"
table(table(enve_nona$CVE_UNICA))
enve_nona %>%
    count(CVE_UNICA) %>%
    summarise(min(n),
              max(n),
              mean(n),
              n())

"number of incidents per state"
enve_nona %>%
    count(CVE_ENT) %>%
    summarise(min(n),
              mean(n),
              max(n),
              n())

"number of businesses per state"
enve_nona %>%
    count(CVE_ENT, CVE_UNICA) %>%
    count(CVE_ENT) %>%
    summarise(min(nn),
              mean(nn),
              max(nn))

```

Calculate the national means of the state-level variables used in the models.

```{r state-level-means}

mean_bribes <- mean(state_level_data$bribes_abvic)
mean_bribes

mean_armas <- mean(state_level_data$armas)
mean_armas

mean_drogas <- mean(state_level_data$drogas)
mean_drogas

mean_poblacion <- mean(state_level_data$poblacion)
mean_poblacion

mean_N <- mean(state_level_data$N)
mean_N

mean_General <- mean(state_level_data$General)
mean_General

mean_Derecho <- mean(state_level_data$Derecho)
mean_Derecho


```

# Part 1

Research questions to cover in this study:

- Are in-person and remote extortion incidents concentrated beyond what is expected by chance? (Calculate locally, just obtain the distributions per type)
- What are the predictors of extortion concentration according to in-person/remote distinction?
    - Are the predictors of prevalence the same as those of concentration for the distinct types?


## Distributions by type

The extortion distributions per type can be easily generated using pipes from tidyverse. However, these distributions are only among victims.

```{r distributions-per-type}


# extortion distribution table, all extortion incidents in victim module

enve_nona %>%
    count(CVE_UNICA) %$%
    table(n)

# extortion distribution table, by extortion type

enve_nona %>%
    count(CVE_UNICA, extortion_type) %$%
    table(n, extortion_type)


# extortion distribution table, by extortion type binary

enve_nona %>%
    count(CVE_UNICA, extortion_type_bin) %$%
    table(n, extortion_type_bin)

enve_nona %>%
    filter(extortion_type_wocp != "Other") %>%
    count(CVE_UNICA, extortion_type_wocp = droplevels(extortion_type_wocp)) %$%
    table(n, extortion_type_wocp)

# Distribution by compliance

enve_nona %>%
    count(CVE_UNICA, complied_bin_NA) %$%
    table(n, complied_bin_NA)


```

For further work, lets aggregate the incidents to business-level, this will also allow calculating the joint distribution per type. These distributions are only among victims.


```{r joint-distributions-1}

enve_nona %>%
    count(CVE_UNICA, extortion_type) %>%
    spread(extortion_type, n, fill = 0) -> counts_per_type

names(counts_per_type)

counts_per_type %$%
    table(Remote, Street)

counts_per_type %$%
    table(Remote, Premises)

counts_per_type %$%
    table(Remote, `Cobro de piso`)

enve_nona %>%
    count(CVE_UNICA, extortion_type_bin) %>%
    spread(extortion_type_bin, n, fill = 0) -> counts_per_type_bin

names(counts_per_type_bin)

counts_per_type_bin %$%
    table(Remote, `In person`)

# Excluding cobro de piso incidents

enve_nona %>%
    filter(extortion_type_wocp != "Other") %>%
    count(CVE_UNICA, extortion_type_wocp) %>%
    spread(extortion_type_wocp, n, fill = 0) -> counts_per_type_wocp

names(counts_per_type_wocp)

counts_per_type_wocp %$%
    table(Remote, `In person`)
```

As these distributions are only among victims of at least one type of extortion incident, the counts must be joined to the general enve table to include non victims as well. Furthermore, the data could also be complemented by counts of the compliance behaviour per type.

```{r incs-to-busns}

enve_nona %>%
    group_by(CVE_UNICA) %>%
    summarise(extincs = n(),
              complied = sum(complied_bin_NA == "Yes"),
              remote = sum(extortion_type == "Remote"),
              street = sum(extortion_type == "Street"),
              premises = sum(extortion_type == "Premises"),
              piso = sum(extortion_type == "Cobro de piso"),
              inperson = sum(extortion_type_bin == "In person"),
              comp_remote  = sum(extortion_type_bin == "Remote" & complied_bin_NA == "Yes"),
              comp_inperson  = sum(extortion_type_bin == "In person" & complied_bin_NA == "Yes"),
              comp_street  = sum(extortion_type == "Street" & complied_bin_NA == "Yes"),
              comp_premises  = sum(extortion_type == "Premises" & complied_bin_NA == "Yes"),
              comp_piso  = sum(extortion_type == "Cobro de piso" & complied_bin_NA == "Yes"),
              inperson_wocp = sum(extortion_type_wocp == "In person"),
              comp_inperson_wocp  = sum(extortion_type_wocp == "In person" & complied_bin_NA == "Yes")) -> enve_bus_lev

### Merge with the enve_test data, keeping non victims as 0

enve_test %>%
    left_join(enve_bus_lev, by = "CVE_UNICA") -> enve_plus


enve_plus %>%
    replace(is.na(.), 0) -> enve_plus_nona

```

Now we can do some joint distributions including victims and non-victims

```{r joint-dists-2}

## overall distribution of extortion incidents

enve_plus_nona %$% table(extincs)

# by binary type

enve_plus_nona %$% table(remote, inperson)

# by binary type, wocp

enve_plus_nona %$% table(remote, inperson_wocp)

# by disaggregated type

enve_plus_nona %$% table(remote, street)

enve_plus_nona %$% table(remote, premises)

enve_plus_nona %$% table(remote, piso)

# street vs premises?

enve_plus_nona %$% table(premises, street)

enve_plus_nona %$% table(premises, piso)

enve_plus_nona %$% table(street, piso)

enve_plus_nona %$% table(inperson_wocp, piso)

## by compliance??

enve_plus_nona %$% table(comp_remote, comp_inperson)

enve_plus_nona %$% table(comp_remote, comp_inperson_wocp)

```

## Models from study 1

In this section, we run some models to explore the predictors of in-person and remote extortion concentration. The focus here is not so much to exhaustively test all the possible predictors, but to replicate the models from study one [@Estevez-Soto2019]. Thus, less emphasis will be placed on finding the ideal model specification, and more on testing the different models available (based on different specifications). Once a suitable type of model is identified, robustness and specification checks can be carried out more systematically.

Specifically, the models to be fit are the truncated models.

Before testing the new extortion counts per type, I will first briefly test the models using the capped extortion counts to compare the estimates to those presented in @Estevez-Soto2019, as they should not be too different.

### Overall extortion concentration

The original model fit in @Estevez-Soto2019 included the following explanatory variables:

- Unit level:
    - corruption victimisations (not logged, but should be logged, try both)
    - business age
    - business type (using full categories)
    - business size
- Area level:
    - corruption prevalence (log)
    - weapon crimes (log)
    - drug crimes (log)
    - n (log)
    - pop (log)
    - competitiveness index (centred)
    - rule of law (centred)

1. Fit the models from study 1
    - Show EDA
    - Use log(bribes) and poly(bribes,2) and compare to bribes
    - Calculate accuracy of Logit models
    - Fit to capped extincs and uncapped extortions
    - Fit using `glmmTMB`, `glmmADMB` and `gamlss` to compare. -- Will not compare to glmmADMB... it takes for ever.
    - Don't forget to test vs poisson and truncated poisson

### EDA First

Do EDA for the variables in model from study 1


```{r eda-study-1}

my_controls <- tableby.control(numeric.test = "kwt", cat.test = "chisq")

s1_formula <-   ~ extortions +
                  bribes +
                  yearsquant +
                  years +
                  subsector_safe +
                  subsector +
                  size


s1_labels <- list(bribes = "Corruption incidence",
                  yearsquant = "Age (quintiles)",
                  years = "Age",
                  subsector_safe = "Business type (all cat.)",
                  subsector = "Business type",
                  size = "Business size")



s1_table <- tableby(s1_formula, data  = enve_plus_nona,
                control = my_controls)

summary(s1_table,
            labelTranslations = s1_labels,
            pfootnote = TRUE)


s1_formula2 <-  update(s1_formula, mkbin(extortions) ~ .)


s1_table2 <- tableby(s1_formula2, data  = enve_plus_nona,
                        control = my_controls)

summary(s1_table2,
            labelTranslations = s1_labels,
            pfootnote = TRUE)


s1_formula3 <-  update(s1_formula, mkbin(extortions, 1) ~ .)


s1_table3 <- tableby(s1_formula3, data  = enve_plus_nona,
                        control = my_controls)

summary(s1_table3,
            labelTranslations = s1_labels,
            pfootnote = TRUE)

## Exclude non victims

s1_table4 <- tableby(s1_formula3,
                        data = subset(enve_plus_nona, extortions > 0),
                        control = my_controls)

summary(s1_table4,
            labelTranslations = s1_labels,
            pfootnote = TRUE)

```

Fit only the truncated models


We first fit the MNB model.

```{r mnb-extortions-vs-extincs}

inc_form <- extortions ~
                bribes +
                yearsquant +
                subsector_safe +
                size +
                mylog(bribes_abvic, mean_bribes) +
                mylog(armas, mean_armas) +
                mylog(drogas, mean_drogas) +
                mylog(N, mean_N) +
                mylog(poblacion, mean_poblacion) +
                scale(General, mean_General, FALSE) +
                scale(Derecho, mean_Derecho, FALSE) +
                (1|NOM_ENT)


mtnb_extortions_admb <- glmmadmb(inc_form,
                        family = "truncnbinom",
                        data = subset(enve_plus_nona, extortions > 0),
                        zeroInflation = FALSE,
                        admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE), extra.args = "-ndi 60000")

countsummary(mtnb_extortions_admb)


# Compare to truncated poisson

mtp_extortions_admb <- update(mtnb_extortions_admb, family = "truncpoiss")

countsummary(mtp_extortions_admb)

compare_nested(mtp_extortions_admb, mtnb_extortions_admb)

## single level truncated models


tnb_extortions <- update(mtnb_extortions_admb, . ~ . - (1|NOM_ENT))

countsummary(tnb_extortions)

compare_nested(tnb_extortions, mtnb_extortions_admb)


# single truncated poisson

tp_extortions <- update(tnb_extortions, family = "truncpoiss")

countsummary(tp_extortions)

compare_nested(tp_extortions, mtp_extortions_admb)

compare_nested(tp_extortions, tnb_extortions)

```


## Modelling according to extortion type


Nonetheless, there are several considerations to make:

- There were no repeats of cobro de piso incidents. Thus it makes no sense to estimate models for concentration and event dependence for these type of incidents.
- Thus, there should be two kinds of in-person category models: with and without cobro de piso incidents.
- Verify results from previous iterations to see if some categories need revising.
- Begin with EDA.
- Compare fit to models without log-transforming bribes.

I will move on to the EDA now.

#### EDA: By extortion type.

First, calculate univariate distributions

```{r univariate-by-type}

enve_plus_nona %$%
    table(remote)


enve_plus_nona %$%
    table(inperson_wocp)

enve_plus_nona %$%
    table(piso)


enve_plus_nona %>%
    select(remote, inperson_wocp, piso) %>%
    melt %>%
    group_by(variable) %>%
    summarise(mean = mean(value),
                variance = var(value),
                ratio = variance/mean)

## Descriptives among victims only
enve_plus_nona %>%
    select(remote, inperson_wocp, piso) %>%
    melt %>%
    group_by(variable) %>%
    filter(value > 0) %>%
    summarise(mean = mean(value),
                variance = var(value),
                ratio = variance/mean)


enve_plus_nona %>%
    select(remote, inperson_wocp) %>%
    melt %>%
    mutate(variable = fct_recode(variable,
            Remote = "remote",
            "In person" = "inperson_wocp")) %>%
    group_by(variable) %>%
    ggplot(aes(value, fill =  variable)) +
    geom_bar() +
    scale_y_sqrt("Businesses") +
    scale_x_continuous(breaks = 0:7) +
    theme_bw() +
    xlab("Incidents per business") +
    facet_wrap(~ variable, scales = "free_y") +
    ggtitle("Distributon of extortion by type (capped at 7)") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/capped_dist_sqrt.pdf", width = 7, height = 4)


enve_plus_nona %>%
    select(remote, inperson_wocp) %>%
    melt %>%
    mutate(variable = fct_recode(variable,
            Remote = "remote",
            "In person" = "inperson_wocp")) %>%
    group_by(variable) %>%
    ggplot(aes(value, fill =  variable)) +
    geom_bar() +
    scale_y_continuous("Businesses", trans = "log1p") +
    scale_x_continuous(breaks = 0:7) +
    theme_bw() +
    xlab("Incidents per business") +
    facet_wrap(~ variable, scales = "free_y") +
    ggtitle("Distributon of extortion by type (capped at 7)") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/capped_dist_log1p.pdf", width = 7, height = 4)


```

Explore univariate extortion distributions


```{r univariate-dist}

victim_table("remote", enve_plus_nona, "pandoc")

victim_table("inperson_wocp", enve_plus_nona, "pandoc")

#kstest

# length of data
ndata <- nrow(enve_plus_nona)

enve_plus_nona %$%
    ks.test(remote, ecdf(rpois(ndata, mean(remote))),
            simulate.p.value = FALSE,
            alternative = "greater")

enve_plus_nona %$%
    ks.test(remote, ecdf(rpois(ndata, mean(remote))),
            simulate.p.value = TRUE,
            alternative = "greater")

enve_plus_nona %$%
    ks.test(inperson_wocp, ecdf(rpois(ndata, mean(inperson_wocp))),
            simulate.p.value = FALSE,
            alternative = "greater")

enve_plus_nona %$%
    ks.test(inperson_wocp, ecdf(rpois(ndata, mean(inperson_wocp))),
            simulate.p.value = TRUE,
            alternative = "greater")

```




It is crucial to identify any issues of complete or quasi-complete separation to avoid estimation errors and problems.

We begin by creating descriptive tables

A table with the prevalence of remote extortion victimisation, per the unit-level variables used in the study.

```{r eda-remote}

eda_remote_formula <-   ~  bribes +
                            yearsquant +
                            years +
                            subsector_safe +
                            subsector +
                            size


eda_remote_labels <- list(bribes = "Corruption incidence",
                  yearsquant = "Age (quintiles)",
                  years = "Age",
                  subsector_safe = "Business type (all cat.)",
                  subsector = "Business type",
                  size = "Business size")



eda_r_table <- tableby(eda_remote_formula,
                        data  = enve_plus_nona,
                        control = my_controls)

summary(eda_r_table,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)


eda_r_formula2 <-  update(eda_remote_formula,
                        mkbin(remote) ~ .)


eda_r_table2 <- tableby(eda_r_formula2, data  = enve_plus_nona,
                        control = my_controls)

summary(eda_r_table2,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)


```

Now generate a table to examine the prevalence or repeat remote extortion victimisation, among all units, and among only victims.


```{r eda-remote-2}


eda_r_formula3 <-  update(eda_remote_formula,
                        mkbin(remote, 1) ~ .)


eda_r_table3 <- tableby(eda_r_formula3, data  = enve_plus_nona,
                        control = my_controls)

summary(eda_r_table3,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)

## now only among victims

eda_r_table4 <- tableby(eda_r_formula3,
                        data  = subset(enve_plus_nona, remote > 0),
                        control = my_controls)

summary(eda_r_table4,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)

```


Repeat for in-person categories without cobro de piso


```{r eda-in-person-wocp}

# Prevalence

eda_ipw_formula <-  update(eda_remote_formula,
                        mkbin(inperson_wocp) ~ .)


eda_ipw_table <- tableby(eda_ipw_formula, data  = enve_plus_nona,
                        control = my_controls)

summary(eda_ipw_table,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)

# Repeat victimisation prevalence


eda_ipw_formula2 <-  update(eda_remote_formula,
                        mkbin(inperson_wocp, 1) ~ .)


eda_ipw_table2 <- tableby(eda_ipw_formula2, data  = enve_plus_nona,
                        control = my_controls)

summary(eda_ipw_table2,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)

## now only among victims

eda_ipw_table3 <- tableby(eda_ipw_formula2,
                        data  = subset(enve_plus_nona, inperson_wocp > 0),
                        control = my_controls)

summary(eda_ipw_table3,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)


```

Next explore prevalence of cobro de piso.

```{r eda-cobro-de-piso}

# Prevalence

eda_cp_formula <-  update(eda_remote_formula,
                        mkbin(piso) ~ .)


eda_cp_table <- tableby(eda_cp_formula, data  = enve_plus_nona,
                        control = my_controls)

summary(eda_cp_table,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)


```



#### Categories adjustments

EDA suggests the following:

- Subsector_safe should not be used
- Subsector is possibly ok for prevalence models, but some concentration models may struggle. It is suggested to consolidate some categories to facilitate comparisons between models (Transport, industry)
- Size and yearquats are acceptable
- The combination of medium and transport leads to complete separation for inperson incidents (in event dependence models).


```{r cat-adjust}

enve_plus_nona$subsector_new <- enve_plus_nona$subsector

levels(enve_plus_nona$subsector_new) <- c('Retail',
                                        'HotelsRestBar',
                                        'Industry' ,
                                        'Industry',
                                        'Other serv.',
                                        'Other serv.',
                                        'Wholesale')

enve_plus_nona %$%
    table(subsector_new)

enve_plus_nona %$%
    table(mkbin(inperson_wocp), subsector_new)

enve_plus_nona %$%
    table(mkbin(piso), subsector_new)

enve_plus_nona %$%
     table(mkbin(remote), subsector_new)


eda_newsub_remote <- tableby(mkbin(remote) ~ subsector_new,
                        data  = enve_plus_nona,
                        control = my_controls)

summary(eda_newsub_remote,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)

eda_newsub_inperson <- tableby(mkbin(inperson_wocp) ~ subsector_new,
                        data  = enve_plus_nona,
                        control = my_controls)

summary(eda_newsub_inperson,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)

eda_newsub_piso <- tableby(mkbin(piso) ~ subsector_new,
                        data  = enve_plus_nona,
                        control = my_controls)

summary(eda_newsub_piso,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)

# repeat victims

eda_newsub_remote <- tableby(mkbin(remote,1) ~ subsector_new,
                        data  = enve_plus_nona,
                        control = my_controls)

summary(eda_newsub_remote,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)

eda_newsub_inperson <- tableby(mkbin(inperson_wocp,1) ~ subsector_new,
                        data  = enve_plus_nona,
                        control = my_controls)

summary(eda_newsub_inperson,
            labelTranslations = eda_remote_labels,
            pfootnote = TRUE)




```


Check state level descriptive statistics of extortion


```{r state-level-descriptives}


# State level prevalence

state_control <- tableby.control(cat.stats = "countrowpct",
                                total = FALSE,
                                test = FALSE)
# remote
eda_state_remote <- tableby(mkbin(remote) ~ NOM_ENT,
                        data  = enve_plus_nona,
                        control = state_control)

summary(eda_state_remote,
            pfootnote = TRUE)

# repeat remote victims

eda_state_remote_repeat <- tableby(mkbin(remote, 1) ~ NOM_ENT,
                        data  = subset(enve_plus_nona, remote > 0),
                        control = state_control)

summary(eda_state_remote_repeat,
            pfootnote = TRUE)


# inperson_wocp

eda_state_inperson <- tableby(mkbin(inperson_wocp) ~ NOM_ENT,
                        data  = enve_plus_nona,
                        control = state_control)

summary(eda_state_inperson,
            pfootnote = TRUE)

# repeat inperson victims

eda_state_inp_repeat <- tableby(mkbin(inperson_wocp, 1) ~ NOM_ENT,
                        data  = subset(enve_plus_nona, inperson_wocp > 0),
                        control = state_control)

summary(eda_state_inp_repeat,
            pfootnote = TRUE)


# Piso victims

eda_state_piso <- tableby(mkbin(piso) ~ NOM_ENT,
                        data  = enve_plus_nona,
                        control = state_control)

summary(eda_state_piso,
            pfootnote = TRUE)

```

These descriptives should point out whether any state should be excluded from the random intercepts (complete separation by state).


#### Remote extortion models

General strategy for the models

- Incidence models first
    - NB vs Poisson (previous iterations suggest NB)
    - Multilevel vs single level (poisson and nb) (previous suggest multilevel better)
    - Fit using log(bribes) and poly(bribes, 2) as informed by previous results
    - truncated models use admb, and start with poisson


```{r remote-incidence-models}

rmt_f <- remote ~ mylog(bribes) +
                    yearsquant +
                    subsector_new +
                    size +
                    mylog(bribes_abvic, mean_bribes) +
                    mylog(armas, mean_armas) +
                    mylog(drogas, mean_drogas) +
                    mylog(N, mean_N) +
                    mylog(poblacion, mean_poblacion) +
                    scale(General, mean_General, FALSE) +
                    scale(Derecho, mean_Derecho, FALSE)

add_nom <- . ~ . + (1|NOM_ENT)

rmt_nb <- glmmTMB(rmt_f,
                    family = "nbinom2",
                    data = enve_plus_nona)

countsummary(rmt_nb)

### Compare Poisson

rmt_p <- update(rmt_nb, family = "poisson")

countsummary(rmt_p)

compare_nested(rmt_p, rmt_nb)


### Test multilevel

rmt_mnb <- update(rmt_nb, add_nom)

countsummary(rmt_mnb)

compare_nested(rmt_mnb, rmt_nb)

## Multilevel poisson

rmt_mp <- update(rmt_p, add_nom)

countsummary(rmt_mp)

compare_nested(rmt_p, rmt_mp)

compare_nested(rmt_mnb, rmt_mp)


## Try different specification for bribes

rmt_mnb_b <- update(rmt_mnb, . ~ + bribes + . - mylog(bribes))

countsummary(rmt_mnb_b)

AICtab(rmt_mnb, rmt_mnb_b)

### Test excluding insignificant variables previously identified
# NS vars:
#           N
#           Derecho

rmt_mnb_pars <- update(rmt_mnb, . ~ . -
                        mylog(N, mean_N) -
                        scale(Derecho, mean_Derecho, FALSE))

countsummary(rmt_mnb_pars)

compare_nested(rmt_mnb_pars, rmt_mnb)

# compare to poisson and single level?

rmt_mp_pars <- update(rmt_mnb_pars, family = "poisson")

countsummary(rmt_mp_pars)

compare_nested(rmt_mp_pars, rmt_mnb_pars)

rmt_nb_pars <- update(rmt_mnb_pars, . ~ . - (1|NOM_CVE))

countsummary(rmt_nb_pars)

compare_nested(rmt_nb_pars, rmt_mnb_pars)

coef_csv(rmt_mnb_pars)
coef_csv(rmt_mnb)

```

Next:

- Prevalence models



```{r remote-prevalence-models}

rmt_logit <- update(rmt_nb, mkbin(remote) ~ . ,
                    family = "binomial")

countsummary(rmt_logit)

# multilevel

rmt_mlogit <- update(rmt_logit, add_nom)

countsummary(rmt_mlogit)

compare_nested(rmt_logit, rmt_mlogit)

# bribes specifications

rmt_mlogit_b <- update(rmt_mlogit, . ~ + bribes + . - mylog(bribes))

countsummary(rmt_mlogit_b)

AICtab(rmt_mlogit, rmt_mlogit_b)

# Parsimonious model

rmt_mlogit_pars <- update(rmt_mnb_pars, mkbin(remote) ~ .,
                            family = "binomial")

countsummary(rmt_mlogit_pars)

compare_nested(rmt_mlogit_pars, rmt_logit)

coef_csv(rmt_mlogit_pars)
coef_csv(rmt_logit)

```


Now do the concentration models (truncated count models)

- Concentration models

```{r remote-concentration-models}

#Start with Truncated Poisson

rmt_vic <-  subset(enve_plus_nona, remote > 0)

rmt_tp <- glmmadmb(rmt_f,
                    family = "truncpoiss",
                    data = rmt_vic,
                    zeroInflation = FALSE,
                    admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE), extra.args = "-ndi 60000")

countsummary(rmt_tp)

## truncated_negbin

rmt_tnb <- update(rmt_tp, family = "truncnbinom")

countsummary(rmt_tnb)

compare_nested(rmt_tp, rmt_nb)

## Multilevel

rmt_mtp <- update(rmt_tp, add_nom)

countsummary(rmt_mtp)

compare_nested(rmt_tp, rmt_mtp)

## multilevel negative binomial

rmt_mtnb <- update(rmt_tnb, add_nom)

countsummary(rmt_mtnb)

compare_nested(rmt_mtp, rmt_mtnb)

compare_nested(rmt_tnb, rmt_mtnb)

### Test bribes functional form

rmt_mtnb_b <- update(rmt_mtnb, . ~ bribes + . - mylog(bribes))

countsummary(rmt_mtnb_b)

AICtab(rmt_mtnb_b, rmt_mtnb)

### Test excluding insignificant variables previously identified
# Significant variables:
#           size (p<0.01)
#           subsector_new (p<0.05)
#           drogas (p<0.1)
#           general (p<0.1)
# Do two rounds, first alpha 0.1, then, alpha 0.05.

# alpha 0.1

rmt_mtp_pars_90 <- update(rmt_mtp, . ~ subsector_new +
                            size +
                            mylog(drogas, mean_drogas) +
                            scale(General, mean_General, FALSE) +
                            (1|NOM_ENT))

countsummary(rmt_mtp_pars_90)

# alpha 0.05

rmt_mtp_pars_95 <- update(rmt_mtp, . ~ subsector_new +
                            size +
                            (1|NOM_ENT))

countsummary(rmt_mtp_pars_95)

compare_nested(rmt_mtp_pars_95, rmt_mtp_pars_90, rmt_mtp)

### tnb pars

rmt_mtnb_pars_90 <- update(rmt_mtnb, . ~ subsector_new +
                            size +
                            mylog(drogas, mean_drogas) +
                            scale(General, mean_General, FALSE) +
                            (1|NOM_ENT))

countsummary(rmt_mtnb_pars_90)

# alpha 0.05

rmt_mtnb_pars_95 <- update(rmt_mtnb, . ~ subsector_new +
                            size +
                            (1|NOM_ENT))

countsummary(rmt_mtnb_pars_95)

compare_nested(rmt_mtnb_pars_95, rmt_mtnb_pars_90, rmt_mtnb)

compare_nested(rmt_mtp_pars_95, rmt_mtnb_pars_95)
compare_nested(rmt_mtp_pars_90, rmt_mtnb_pars_90)

## single level nb pars

rmt_tnb_pars_90 <- update(rmt_mtnb_pars_90, . ~ . - (1|NOM_ENT))

countsummary(rmt_tnb_pars_90)

compare_nested(rmt_tnb_pars_90, rmt_mtnb_pars_90)

# alpha 0.05

rmt_tnb_pars_95 <- update(rmt_mtnb_pars_95, . ~ . - (1|NOM_ENT))

countsummary(rmt_tnb_pars_95)

compare_nested(rmt_tnb_pars_95, rmt_mtnb_pars_95)

coef_csv(rmt_mtnb)
coef_csv(rmt_mtnb_pars_90)
coef_csv(rmt_mtnb_pars_95)

```



#### Inperson_wocp extortion models

General strategy for the models

- Incidence models first
    - NB vs Poisson (previous iterations suggest NB)
    - Multilevel vs single level (poisson and nb) (previous suggest multilevel better)
    - Test log(bribes) and poly(bribes, 2) as a sanity check

```{r in-person-incidence}


inp_f <- update(rmt_f, inperson_wocp ~ poly(bribes, 2, raw = TRUE) + . - mylog (bribes))

inp_p <- glmmTMB(inp_f,
                    family = "poisson",
                    data = enve_plus_nona)

countsummary(inp_p)

### Compare Poisson

inp_nb <- update(inp_p, family = "nbinom2")

countsummary(inp_nb)

compare_nested(inp_p, inp_nb)

## Multilevel poisson

inp_mp <- update(inp_p, add_nom)

countsummary(inp_mp)

compare_nested(inp_p, inp_mp)

### Test nbinom multilevel

inp_mnb <- update(inp_mp, family = "nbinom2")

countsummary(inp_mnb)

compare_nested(inp_nb, inp_mnb)

compare_nested(inp_mp, inp_mnb)


## Try different specification for bribes
# log bribes

inp_mnb_lb <- update(inp_mnb, . ~ mylog(bribes) + . -
                        poly(bribes, 2, raw = TRUE))

countsummary(inp_mnb_lb)

AICtab(inp_mnb, inp_mnb_lb)

#  linear bribes

inp_mnb_b <- update(inp_mnb_lb, . ~ bribes + . - mylog(bribes))

countsummary(inp_mnb_b)

AICtab(inp_mnb, inp_mnb_lb, inp_mnb_b)

### Test excluding insignificant variables previously identified
# Significant vars:
#           bribes      p<0.001
#           armas       p<0.05
#           drogas      p<0.05
#           yearsquant  p<0.1
#           subsector   p<0.1

# alpha 0.1
inp_mnb_pars_90 <- update(inp_mnb, . ~ poly(bribes, 2, raw = TRUE) +
                                    yearsquant +
                                    subsector_new +
                                    mylog(armas, mean_armas) +
                                    mylog(drogas, mean_drogas) +
                                    (1|NOM_ENT)
                                )
countsummary(inp_mnb_pars_90)

# alpha 0.05

inp_mnb_pars_95 <- update(inp_mnb_pars_90, . ~ . - yearsquant - subsector_new)

countsummary(inp_mnb_pars_95)

compare_nested(inp_mnb_pars_95, inp_mnb_pars_90, inp_mnb)

# compare to poisson

# alpha 0.1
inp_mp_pars_90 <- update(inp_mnb_pars_90, family = "poisson")

countsummary(inp_mp_pars_90)

compare_nested(inp_mp_pars_90, inp_mnb_pars_90)

# alpha 0.05

inp_mp_pars_95 <- update(inp_mp_pars_90, . ~ . - yearsquant - subsector_new)

countsummary(inp_mp_pars_95)

compare_nested(inp_mp_pars_95, inp_mnb_pars_95)

## single level nb

# alpha 0.1
inp_nb_pars_90 <- update(inp_mnb_pars_90, . ~ . - (1|NOM_ENT))

countsummary(inp_nb_pars_90)

compare_nested(inp_nb_pars_90, inp_mnb_pars_90)

# alpha 0.05

inp_nb_pars_95 <- update(inp_mnb_pars_95, . ~ . - (1|NOM_ENT))

countsummary(inp_nb_pars_95)

compare_nested(inp_nb_pars_95, inp_mnb_pars_95)

## save to csv

coef_csv(inp_mnb)
coef_csv(inp_mnb_pars_90)
coef_csv(inp_mnb_pars_95)

```

- Prevalence models


```{r in-person-prevalence}


inp_logit <- update(inp_p, mkbin(inperson_wocp) ~ . ,
                    family = "binomial")

countsummary(inp_logit)

# multilevel

inp_mlogit <- update(inp_logit, add_nom)

countsummary(inp_mlogit)

compare_nested(inp_logit, inp_mlogit)


# bribes specifications

inp_mlogit_lb <- update(inp_mlogit, . ~ mylog(bribes) + . -
                        poly(bribes, 2, raw = TRUE) )

countsummary(inp_mlogit_lb)

AICtab(inp_mlogit, inp_mlogit_lb)

inp_mlogit_b <- update(inp_mlogit_lb,  . ~ + bribes + . -mylog(bribes))

countsummary(inp_mlogit_b)

AICtab(inp_mlogit, inp_mlogit_lb, inp_mlogit_b)

### Test excluding insignificant variables previously identified
# Significant vars:
#           bribes      p<0.001
#           armas       p<0.05
#           drogas      p<0.01
#           yearsquant  p<0.05
#           subsector   NS but keep for comparison

# including subsector
inp_mlogit_pars_90 <- update(inp_mlogit, . ~ poly(bribes, 2, raw = TRUE) +
                                    yearsquant +
                                    subsector_new +
                                    mylog(armas, mean_armas) +
                                    mylog(drogas, mean_drogas) +
                                    (1|NOM_ENT)
                                )
countsummary(inp_mlogit_pars_90)

# alpha 0.05

inp_mlogit_pars_95 <- update(inp_mlogit_pars_90, . ~ . - subsector_new)

countsummary(inp_mlogit_pars_95)

compare_nested(inp_mlogit_pars_95, inp_mlogit_pars_90, inp_mlogit)

## single level

# including subsector
inp_logit_pars_90 <- update(inp_mlogit_pars_90, . ~ . - (1|NOM_ENT))

countsummary(inp_logit_pars_90)

compare_nested(inp_logit_pars_90, inp_mlogit_pars_90)

# alpha 0.05

inp_logit_pars_95 <- update(inp_mlogit_pars_95, . ~ . - (1|NOM_ENT))

countsummary(inp_logit_pars_95)

compare_nested(inp_logit_pars_95, inp_mlogit_pars_95)

## save to csv

coef_csv(inp_mlogit)
coef_csv(inp_mlogit_pars_90)
coef_csv(inp_mlogit_pars_95)


```

- Concentration models
    - tnb vs tp (previous suggest NB)
    - glmmADMB vs glmmTMB
    - multilevel specs

```{r in-person-concentration}

inp_vic <-  subset(enve_plus_nona, inperson_wocp > 0)

inp_tp <- glmmadmb(inp_f,
                    family = "truncpoiss",
                    data = inp_vic,
                    zeroInflation = FALSE,
                    admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE), extra.args = "-ndi 60000")

countsummary(inp_tp)

## truncated_negbin

inp_tnb <- update(inp_tp, family = "truncnbinom")

countsummary(inp_tnb)

compare_nested(inp_tp, inp_nb)

## Multilevel

inp_mtp <- update(inp_tp, add_nom)

countsummary(inp_mtp)

compare_nested(inp_tp, inp_mtp)

## multilevel negative binomial

inp_mtnb <- update(inp_tnb, add_nom)

countsummary(inp_mtnb)

compare_nested(inp_mtp, inp_mtnb)

compare_nested(inp_tnb, inp_mtnb)

# ### Test bribes functional form?
# No need, bribes not significant

### Test excluding insignificant variables previously identified
# Significant variables:
#           subsector_new (p<0.1)

inp_tp_pars <- update(inp_tp, . ~ subsector_new)

countsummary(inp_tp_pars)

compare_nested(inp_tp_pars, inp_tp)

## multilevel

inp_mtp_pars <- update(inp_mtp, . ~ subsector_new + (1|NOM_ENT))

countsummary(inp_mtp_pars)

compare_nested(inp_mtp_pars, inp_mtp)

coef_csv(inp_tp)
coef_csv(inp_mtp)
coef_csv(inp_tp_pars)
coef_csv(inp_mtp_pars)

```


#### Piso extortion models

General strategy for the models

- Prevalence models
    - Single level vs multilevel


```{r piso-prevalence}

piso_f <- update(rmt_f, mkbin(piso) ~ . )

piso_logit <- glmmTMB(piso_f, data = enve_plus_nona, family = "binomial")

countsummary(piso_logit)

# multilevel

piso_mlogit <- update(piso_logit, . ~ . + (1|CVE_ENT))

countsummary(piso_mlogit)

compare_nested(piso_logit, piso_mlogit)

# bribes specifications

piso_mlogit_b <- update(piso_mlogit, . ~ bribes + . - mylog(bribes))

countsummary(piso_mlogit_lb)

AICtab(piso_mlogit, piso_mlogit_lb)

### Test excluding insignificant variables previously identified
# Significant variables:
#           log(bribes) (p<0.05)
#           general     (p<0.01)
#           derecho     (p<0.001 in logit)

# multilevel
# with derecho
piso_mlogit_pars_der <- update(piso_mlogit, . ~ mylog(bribes) +
                                scale(General, mean_General, FALSE) +
                                scale(Derecho, mean_General, FALSE)
                            )

countsummary(piso_mlogit_pars_der)

compare_nested(piso_mlogit_pars_der, piso_mlogit)

# without derecho

piso_mlogit_pars_95 <- update(piso_mlogit_pars_der, . ~ . -
                                scale(Derecho, mean_General, FALSE)
                            )

countsummary(piso_mlogit_pars_95)

compare_nested(piso_mlogit_pars_95, piso_mlogit_pars_der, piso_mlogit)

# single level

piso_logit_pars_der <- update(piso_logit, . ~ mylog(bribes) +
                                scale(General, mean_General, FALSE) +
                                scale(Derecho, mean_General, FALSE)
                            )

countsummary(piso_logit_pars_der)

compare_nested(piso_logit_pars_der, piso_mlogit_pars_der)

# without derecho

piso_logit_pars_95 <- update(piso_logit_pars_der, . ~ . -
                                scale(Derecho, mean_General, FALSE)
                            )

countsummary(piso_logit_pars_95)

compare_nested(piso_logit_pars_95, piso_mlogit_pars_95)

```


# Event dependence study

Several things to improve over previous iteration.

Time course analysis:

Do EDA of victimisation frequency per month and semester

Redo timecourse plots, make sure they are correctly saved in the figure folder. Also add labels for every month.

When excluding semester wise observations that have reached the cap, mention how many had to be excluded.

Fix case compliance variable, change OR for AND

After lag adjust, fit to

Do plots of lag adjusted to get a sense of how many there are.

Also do a scatter plot vs unadjusted? (can exclude zeroes)

Fix compliance formulas

As previous chapter showed incidence not best approach, maybe focus only on prevalence vs concentration here. Fit only relevant variables and focus on event dependence.

## Time course


```{r time-course}

table(enve_nona$month, useNA = "ifany")

sum(table(enve_nona$month, useNA = "ifany"))

enve_nona %>%
    filter(month < 13) %$%
    table(month, useNA = "ifany") %>% sum

enve_nona %>%
    filter(month < 13) %$%
    table(month, useNA = "ifany")

enve_nona %>%
    filter(month < 13) %$%
    table(month, useNA = "ifany") %>%
    chisq.test(.)


## Tables and tests by type

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "Remote") %$%
    table(month, useNA = "ifany")

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "Remote") %$%
    table(month, useNA = "ifany")%>%
    chisq.test

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "In person") %$%
    table(month, useNA = "ifany")

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "In person") %$%
    table(month, useNA = "ifany")%>%
    chisq.test

# plots
enve_nona %>%
    filter(month < 13) %>%
    ggplot(aes(month)) +
    geom_bar() +
    theme_bw() +
    scale_x_continuous("Month", breaks = 1:12) +
    ylab("Extortion incidents") +
    ggtitle("Monthly count of extortion incidents")


enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp != "Other") %>%
    ggplot(aes(month, fill = extortion_type_wocp)) +
    geom_bar() +
    theme_bw() +
    scale_x_continuous("Month", breaks = 1:12) +
    ylab("Extortion incidents") +
    ggtitle("Extortion incidents (monthly)") +
    facet_wrap(~ extortion_type_wocp, scales = "free_y") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/monthly_counts_extortion.pdf", width = 7, height = 4)


# events per semester

enve_nona %>%
    filter(month < 13) %>%
    mutate(sem = case_when(
        month < 7   ~ 0,
        month >= 7  ~ 1
    ))%$%
    table(sem, useNA = "ifany")

enve_nona %>%
    filter(month < 13) %>%
    mutate(sem = case_when(
        month < 7   ~ 0,
        month >= 7  ~ 1
    ))%$%
    table(sem, useNA = "ifany") %>%
    chisq.test

### per type

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "In person") %>%
    mutate(sem = case_when(
        month < 7   ~ 0,
        month >= 7  ~ 1
    )) %$%
    table(sem, useNA = "ifany")

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "In person") %>%
    mutate(sem = case_when(
        month < 7   ~ 0,
        month >= 7  ~ 1
    ))%$%
    table(sem, useNA = "ifany") %>%
    chisq.test

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "Remote") %>%
    mutate(sem = case_when(
        month < 7   ~ 0,
        month >= 7  ~ 1
    )) %$%
    table(sem, useNA = "ifany")

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "Remote") %>%
    mutate(sem = case_when(
        month < 7   ~ 0,
        month >= 7  ~ 1
    ))%$%
    table(sem, useNA = "ifany") %>%
    chisq.test


#### TC
enve_nona %>%
    filter(month < 13) %>%
    #select(CVE_UNICA, month) %>%
    arrange(CVE_UNICA, month) -> id_mth

id_mth %>%
    group_by(CVE_UNICA) %>%
    mutate(lmonth = lag(month)) %>%
    drop_na %>%
    mutate(tc = month - lmonth) -> mth_tc

table(mth_tc$tc)

prop.table(table(mth_tc$tc))

# Calculate summary statistics for time course

mth_tc %>%
    ungroup %>%
    summarise(mean(tc),
              var(tc))



data.frame(table(mth_tc$tc)) %>%
    transmute(time = as.integer(as.character(Var1)),
                count = Freq,
                prop = count/sum(count)) -> tc_df

tc_df


tc_smooth_log <- glm(prop ~ time, data = tc_df,
                    family = gaussian(link = "log"))

summary(tc_smooth_log)

lrtest(tc_smooth_log)



half_life(tc_smooth_log)

### Add model to ggplot functionise


(tc_df %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"), colour = "black",
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat extortion victimisation") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
            scale_x_continuous(breaks = 0:11) +
            scale_y_continuous(labels = scales::percent) -> tc1)

ggsave(tc1, filename = "figure/time_course_full.pdf")


# Use filter to select second semester
### Correct for time window effect

mth_tc %>%
    filter(month > 5) %>%
    filter(tc < 7) %$%
    table(tc) %>%
    data.frame %>%
    transmute(time = as.integer(as.character(tc)),
                count = Freq,
                prop = count/sum(count))  -> tc_df_6m

tc_df_6m


### summary statistics

## all obs
mth_tc %>%
    ungroup %>%
    summarise(mean(tc),
              var(tc))

## Time window effect

mth_tc %>%
    ungroup %>%
    filter(month > 5) %>%
    filter(tc < 7) %>%
    summarise(mean(tc),
              var(tc))


tc_6m_smooth <- glm(prop ~ time, data = tc_df_6m,
                    family = gaussian(link = "log"))

summary(tc_6m_smooth)

lrtest(tc_6m_smooth)

half_life(tc_6m_smooth)



(tc_df_6m %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"), colour = "black",
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat extortion victimisation (6 month window)") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
            scale_x_continuous(breaks = 0:11) +
            scale_y_continuous(labels = scales::percent) -> tc2)

ggsave(tc2, file = "figure/time_course_6m_window.pdf")
```


### Time course for remote extortions

To analyse the time course per event type, the TC column must be recalculated after subsetting events by type.


```{r time-course-remote}

# filter data set using the following
id_mth %>%
    filter(extortion_type_wocp == "Remote") %>%
    group_by(CVE_UNICA) %>%
    mutate(lmonth = lag(month)) %>%
    drop_na %>%
    mutate(tc = month - lmonth) -> tc_remote

### Calculate time courses using:

### Full period
tc_remote %$%
    table(tc) %>%
    data.frame %>%
    transmute(time = as.integer(as.character(tc)),
                count = Freq,
                prop = count/sum(count)) -> tc_remote_tb

tc_remote_tb


tc_remote_model <- glm(prop ~ time, data = tc_remote_tb,
                    family = gaussian(link = "log"))

summary(tc_remote_model)

lrtest(tc_remote_model)


half_life(tc_remote_model)


tc_remote_tb %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"), colour = "black",
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat remote extortion victimisation") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom")  +
            scale_x_continuous(breaks = 0:11) +
            scale_y_continuous(labels = scales::percent)




## 6m time window

tc_remote %>%
    filter(month > 5) %>%
    filter(tc < 7) %$%
    table(tc) %>%
    data.frame %>%
    transmute(time = as.integer(as.character(tc)),
                count = Freq,
                prop = count/sum(count)) -> tc_remote_6m_tb

tc_remote_6m_tb

tc_remote_model_6m <- glm(prop ~ time, data = tc_remote_6m_tb,
                    family = gaussian(link = "log"))

summary(tc_remote_model_6m)

lrtest(tc_remote_model_6m)


half_life(tc_remote_model_6m)


tc_remote_6m_tb %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"), colour = "black",
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat remote extortion victimisation \n(6 month time window)") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
            scale_x_continuous(breaks = 0:11) +
            scale_y_continuous(labels = scales::percent)


```


### Time course for in-person extortions

Now we estiamte the time course for in-persone extortions (excluding of course cobro de piso, as these do not have repeats).


```{r time-course-in-person}

# filter data set using the following

id_mth %>%
    filter(extortion_type_wocp == "In person") %>%
    group_by(CVE_UNICA) %>%
    mutate(lmonth = lag(month)) %>%
    drop_na %>%
    mutate(tc = month - lmonth) -> tc_inp

### Calculate time courses using:

### Full period
tc_inp %$%
    table(tc) %>%
    data.frame %>%
    transmute(time = as.integer(as.character(tc)),
                count = Freq,
                prop = count/sum(count)) -> tc_inp_tb

tc_inp_tb


tc_inp_model <- glm(prop ~ time, data = tc_inp_tb,
                    family = gaussian(link = "log"))

summary(tc_inp_model)

lrtest(tc_inp_model)


half_life(tc_inp_model)


tc_inp_tb %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"), colour = "black",
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat in-person extortion victimisation") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
            scale_x_continuous(breaks = 0:11) +
            scale_y_continuous(labels = scales::percent)




## 6m time window

tc_inp %>%
    filter(month > 5) %>%
    filter(tc < 7) %$%
    table(tc) %>%
    data.frame %>%
    transmute(time = as.integer(as.character(tc)),
                count = Freq,
                prop = count/sum(count)) -> tc_inp_6m_tb

tc_inp_6m_tb

tc_inp_model_6m <- glm(prop ~ time, data = tc_inp_6m_tb,
                    family = gaussian(link = "log"))

summary(tc_inp_model_6m)

lrtest(tc_inp_model_6m)


half_life(tc_inp_model_6m)


tc_inp_6m_tb %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"), colour = "black",
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat remote extortion victimisation \n(6 month time window)") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
            scale_x_continuous(breaks = 0:11) +
            scale_y_continuous(labels = scales::percent)


```


Generate a plot combining the time course of both types

```{r combined-time-course}


tc_remote_tb %>%
    mutate(Type = "Remote extortion") %>%
    bind_rows(mutate(tc_inp_tb, Type = "In-person extortion")) -> tc_both


(tc_both %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"),
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat extortion victimisation") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
    facet_wrap(~ Type)  +
    scale_x_continuous(breaks = 0:11) +
    scale_y_continuous(labels = scales::percent)  -> tc_both_p1)

ggsave(tc_both_p1, file = "figure/tc_both_p1.pdf",
        width = 8, height = 4)

## using 6m time window

tc_remote_6m_tb %>%
    mutate(Type = "Remote extortion") %>%
    bind_rows(mutate(tc_inp_6m_tb, Type = "In-person extortion")) -> tc_both_6m


(tc_both_6m %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"),
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat extortion victimisation \n(6 month time window)") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
    facet_wrap(~ Type)  +
    scale_x_continuous(breaks = 0:11) +
    scale_y_continuous(labels = scales::percent)  -> tc_both_6m_p1)

ggsave(tc_both_6m_p1, file = "figure/tc_both_6m_p1.pdf",
        width = 7, height = 4)

```

## Modelling event dependence

One option is to divide the extortion observation into at least two periods, e.g. first and second semester, and model the prevalence, incidence and concentration of extortion in the second semester, with the count for the previous semester as a covariate. This is simple, but has several limitations. If the time-course of repeat victimisation suggests a rapid decay in victimisation risk, then there will be very few businesses that faced victimisation the previous semester---event dependence won't be captured and will be a part of unobserved heterogeneity. Second, the lagged covariate will likely be correlated with the additional time-invariant covariates, which could bias the results. (Capping adjustments or categorical variables may mitigate this)

Another option is to build a longer panel and control for unit fixed effects, that way the time-invariant covariates would not be needed: they could be dropped. An additional advantage would be that this approach would be able to capture event dependence with a steeper decay function---capturing the effect of event dependence between months, instead of semesters. The `pglm` package could be used for panel logit and count models. A problem is that observations would very likely be serially correlated, and I am unsure if there are suitable methods to detect and correct serial correlation for negbin models. This approach could also magnify any measurement errors in the way event and month data is captured, which has not been fully examined. The longer the panel, the more error would be introduced as we would be synthetically creating a panel based on cross-sectional measurements.

For this exercise, I believe a two semester panel is a good compromise between the amount of error that is introduced and the explanatory power of the model.

Another complication is that as the data is capped, the number of observations in the lagged count is a function of the number of counts in the dependent variable (or in other extortion events). Thus the Event Dependence indicator should account for this and represent instead the number of incidents suffered over the maximum number of incidents that a unit could suffer--however, this might require dropping observations that reach the cap in semester 2 (that are incapable of suffering an event in semester 1 due to the amount of events suffered in semester 2).

Lastly, it would be particularly interesting to explore not only if the amount of victimisation suffered in the previous semester is a predictor, but also if complying with an event has implications for event dependence. A good approach to operationalise this would be using categorical variables (not a victim, victim did not comply, victim-complied).

### Data wrangling

Before the analysis, a data frame splitting the extortion counts by semester must be constructed.

Then select only observations from semester 2.

Models for lag dependence should exclude those observations where it is impossible to suffer extortions in one period because the cap is reached in one semester. These situations would occour if:

- extincs (in sem 2) is 7
- lag_extincs (in sem1) is 7

Previous iterations of the analysis suggest that there are some cases where this happens.

In extincs there are 6 cases that are equal to 7, similarly there are 6 cases where lag_extincs is 7.


```{r semester-counts}

# Create a semester column

enve_nona %>%
    mutate(semester = ifelse(month < 7, 0,
                    ifelse(month > 12, 99, 1))) -> enve_mths_plus


enve_mths_plus %$%
    table(semester, useNA = "ifany")

# Identify CVE_UNICAS with no month

enve_mths_plus %>%
    filter(semester == 99) %$%
    unique(CVE_UNICA) -> non_month_cu

## Add semester as grouping factor

enve_mths_plus %>%
    group_by(CVE_UNICA, semester) %>%
    filter(semester != 99) %>%
    summarise(extincs = n(),
              complied = sum(complied_bin_NA == "Yes"),
              remote = sum(extortion_type == "Remote"),
              piso = sum(extortion_type == "Cobro de piso"),
              inperson = sum(extortion_type_wocp == "In person"),
              comp_remote  = sum(extortion_type_bin == "Remote" & complied_bin_NA == "Yes"),
              comp_inperson  = sum(extortion_type_wocp == "In person" & complied_bin_NA == "Yes")) %>%
              complete(CVE_UNICA,
                  semester = c(0,1)) %>%
              replace(is.na(.), 0) -> enve_bus_lev_semester

enve_bus_lev_semester %$%
    table(semester, useNA = "ifany")

enve_bus_lev_semester %$%
    CVE_UNICA %in% non_month_cu %>% table


enve_bus_lev %>%
    group_by(CVE_UNICA) %>%
    summarise(n = max(extincs)) %$% range(n)

enve_bus_lev_semester %>%
    group_by(CVE_UNICA, semester) %>%
    summarise(n = max(extincs)) %$% range(n)

### Merge with the enve_test data, keeping non victims as 0

enve_test %$%
    data.frame(CVE_UNICA = rep(CVE_UNICA, each = 2),
                semester = 0:1) -> enve_ids_semester

enve_test %>%
    left_join(enve_ids_semester, by = "CVE_UNICA") -> enve_plus_ids_sem

enve_plus_ids_sem %>%
    left_join(enve_bus_lev_semester) -> enve_plus_sem

enve_plus_sem %$%
    table(semester, useNA = "ifany")


enve_plus_sem %>%
    group_by(semester) %>%
    summarise(max(extincs))

enve_plus_sem %>%
    replace(is.na(.), 0) -> enve_sem_nona

enve_sem_nona %>%
    group_by(semester) %>%
    summarise(max(extincs))

nrow(enve_plus_sem)

nrow(enve_sem_nona)


## Add lagged columns for all capped counts

enve_sem_nona %>%
    group_by(CVE_UNICA) %>%
    mutate(lag_extincs = lag(extincs, order_by = semester),
            lag_remote = lag(remote, order_by = semester),
            lag_inperson = lag(inperson, order_by = semester),
            lag_piso = lag(piso, order_by = semester),
            lag_complied = lag(complied, order_by = semester),
            lag_comp_remote = lag(comp_remote, order_by = semester),
            lag_comp_inperson = lag(comp_inperson,
                order_by = semester)) -> enve_sem_lag


length(non_month_cu)

enve_sem_lag %>%
    filter(!CVE_UNICA %in% non_month_cu) -> enve_lag_nm

nrow(enve_lag_nm)

enve_sem_lag %$%
    table(extincs)

enve_lag_nm %$%
    table(extincs)

enve_sem_lag %$%
    table(remote)

enve_lag_nm %$%
    table(remote)

enve_sem_lag %$%
    table(inperson)

enve_lag_nm %$%
    table(inperson)

### select semester 2
# Exclude obs where Cap is reached one semester

enve_lag_nm %>%
    filter(semester > 0) %>%
    filter(extincs < 7) %>%
    filter(lag_extincs < 7) -> enve_lag_nm_sem1


enve_lag_nm_sem1 %$%
    table(extincs)

enve_lag_nm_sem1 %$%
    table(lag_extincs)

enve_lag_nm_sem1 %$%
    table(remote)

enve_lag_nm_sem1 %$%
    table(lag_remote)

enve_lag_nm_sem1 %$%
    table(inperson)

enve_lag_nm_sem1 %$%
    table(lag_inperson)

## Add subsector new category

enve_lag_nm_sem1$subsector_new <- enve_lag_nm_sem1$subsector

levels(enve_lag_nm_sem1$subsector_new) <- c('Retail',
                                        'HotelsRestBar',
                                        'Industry' ,
                                        'Industry',
                                        'Other serv.',
                                        'Other serv.',
                                        'Wholesale')


```

### EDA

Do extensive EDA to understand if any variable has complete or quasi-complete separation (business and state level)

Examine EDA (and models) from previous iterations see if some categories indicate complete or quasi-complete separation.


```{r semester-eda}

### For overall extortions first


ed_extincs_eda_f <- mkbin(extincs) ~ factor(mkbin(lag_extincs)) +
                                   factor(mkbin(lag_complied)) +
                                   bribes +
                                   yearsquant +
                                   size +
                                   subsector_new

ed_extincs_eda <- tableby(ed_extincs_eda_f,
                        data  = enve_lag_nm_sem1,
                        control = my_controls)

summary(ed_extincs_eda,
            pfootnote = TRUE)

## repeat extortions

ed_extincs_eda_f_repeats <- mkbin(extincs, 1) ~ factor(mkbin(lag_extincs)) +
                                   factor(mkbin(lag_complied)) +
                                   bribes +
                                   yearsquant +
                                   size +
                                   subsector_new

ed_extincs_eda_reps <- tableby(ed_extincs_eda_f_repeats,
                        data  = enve_lag_nm_sem1,
                        control = my_controls)

summary(ed_extincs_eda_reps,
            pfootnote = TRUE)


#### Remote extortions

ed_remote_eda_f <- mkbin(remote) ~ factor(mkbin(lag_remote)) +
                                   factor(mkbin(lag_comp_remote)) +
                                   bribes +
                                   yearsquant +
                                   size +
                                   subsector_new

ed_remote_eda <- tableby(ed_remote_eda_f,
                        data  = enve_lag_nm_sem1,
                        control = my_controls)

summary(ed_remote_eda,
            pfootnote = TRUE)

## repeat extortions

ed_remote_eda_f_repeats <- mkbin(remote, 1) ~ factor(mkbin(lag_remote)) +
                                   factor(mkbin(lag_comp_remote)) +
                                   bribes +
                                   yearsquant +
                                   size +
                                   subsector_new

ed_remote_eda_reps <- tableby(ed_remote_eda_f_repeats,
                        data  = enve_lag_nm_sem1,
                        control = my_controls)

summary(ed_remote_eda_reps,
            pfootnote = TRUE)

#### In person extortions

ed_inp_eda_f <- mkbin(inperson) ~ factor(mkbin(lag_inperson)) +
                                   factor(mkbin(lag_comp_inperson)) +
                                   bribes +
                                   yearsquant +
                                   size +
                                   subsector_new

ed_inp_eda <- tableby(ed_inp_eda_f,
                        data  = enve_lag_nm_sem1,
                        control = my_controls)

summary(ed_inp_eda,
            pfootnote = TRUE)

## repeat extortions

ed_inp_eda_f_repeats <- mkbin(inperson, 1) ~ factor(mkbin(lag_inperson)) +
                                   factor(mkbin(lag_comp_inperson)) +
                                   bribes +
                                   yearsquant +
                                   size +
                                   subsector_new

ed_inp_eda_reps <- tableby(ed_inp_eda_f_repeats,
                        data  = enve_lag_nm_sem1,
                        control = my_controls)

summary(ed_inp_eda_reps,
            pfootnote = TRUE)

```

EDA by state

```{r state-level-descriptives-event-dependence}


# State level prevalence

state_control <- tableby.control(cat.stats = "countrowpct",
                                total = FALSE,
                                test = FALSE)
# remote
eda_state_remote_ed <- tableby(mkbin(remote) ~ NOM_ENT,
                        data  = enve_lag_nm_sem1,
                        control = state_control)

summary(eda_state_remote_ed,
            pfootnote = TRUE)

# repeat remote victims

eda_state_remote_repeat_ed <- tableby(mkbin(remote, 1) ~ NOM_ENT,
                        data  = subset(enve_lag_nm_sem1, remote > 0),
                        control = state_control)

summary(eda_state_remote_repeat_ed,
            pfootnote = TRUE)


# inperson_wocp

eda_state_inperson_ed <- tableby(mkbin(inperson) ~ NOM_ENT,
                        data  = enve_lag_nm_sem1,
                        control = state_control)

summary(eda_state_inperson_ed,
            pfootnote = TRUE)

# repeat inperson victims

eda_state_inp_repeat_ed <- tableby(mkbin(inperson, 1) ~ NOM_ENT,
                        data  = subset(enve_lag_nm_sem1, inperson > 0),
                        control = state_control)

summary(eda_state_inp_repeat_ed,
            pfootnote = TRUE)


```

Plot and table distribution


```{r ed-plots-tables}

# Semester 1

enve_lag_nm_sem1 %>%
    ungroup %>%
    select(remote, inperson) %>%
    melt %>%
    mutate(variable = fct_recode(variable,
            Remote = "remote",
            "In person" = "inperson")) %>%
    group_by(variable) %>%
    ggplot(aes(value, fill =  variable)) +
    geom_bar() +
    scale_y_sqrt("Businesses") +
    scale_x_continuous(breaks = 0:7) +
    theme_bw() +
    xlab("Incidents per business") +
    facet_wrap(~ variable, scales = "free_y") +
    ggtitle("Distributon of extortion by type (capped at 7)",
            subtitle = "Second semester of 2014") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/capped_dist_sqrt_sem1.pdf", width = 7, height = 4)


enve_lag_nm_sem1 %>%
    ungroup %>%
    select(remote, inperson) %>%
    melt %>%
    mutate(variable = fct_recode(variable,
            Remote = "remote",
            "In person" = "inperson")) %>%
    group_by(variable) %>%
    ggplot(aes(value, fill =  variable)) +
    geom_bar() +
    scale_y_continuous("Businesses", trans = "log1p") +
    scale_x_continuous(breaks = 0:7) +
    theme_bw() +
    xlab("Incidents per business") +
    facet_wrap(~ variable, scales = "free_y") +
    ggtitle("Distributon of extortion by type (capped at 7)",
            subtitle = "Second semester of 2014") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/capped_dist_log1p_sem1.pdf", width = 7, height = 4)


# Semester 2

enve_lag_nm_sem1 %>%
    ungroup %>%
    select(lag_remote, lag_inperson) %>%
    melt %>%
    mutate(variable = fct_recode(variable,
            Remote = "lag_remote",
            "In person" = "lag_inperson")) %>%
    group_by(variable) %>%
    ggplot(aes(value, fill =  variable)) +
    geom_bar() +
    scale_y_sqrt("Businesses") +
    scale_x_continuous(breaks = 0:7) +
    theme_bw() +
    xlab("Incidents per business") +
    facet_wrap(~ variable, scales = "free_y") +
    ggtitle("Distributon of extortion by type (capped at 7)",
            subtitle = "First semester of 2014") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/capped_dist_sqrt_sem0.pdf", width = 7, height = 4)


enve_lag_nm_sem1 %>%
    ungroup %>%
    select(lag_remote, lag_inperson) %>%
    melt %>%
    mutate(variable = fct_recode(variable,
            Remote = "lag_remote",
            "In person" = "lag_inperson")) %>%
    group_by(variable) %>%
    ggplot(aes(value, fill =  variable)) +
    geom_bar() +
    scale_y_continuous("Businesses", trans = "log1p") +
    scale_x_continuous(breaks = 0:7) +
    theme_bw() +
    xlab("Incidents per business") +
    facet_wrap(~ variable, scales = "free_y") +
    ggtitle("Distributon of extortion by type (capped at 7)",
            subtitle = "First semester of 2014") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/capped_dist_log1p_sem0.pdf", width = 7, height = 4)

## tables

enve_lag_nm_sem1 %$%
    victim_table(remote, "pandoc")

enve_lag_nm_sem1 %$%
    victim_table(lag_remote, "pandoc")

enve_lag_nm_sem1 %$%
    victim_table(inperson, "pandoc")

enve_lag_nm_sem1 %$%
    victim_table(lag_inperson, "pandoc")


```


### Modelling

Modelling:

- Prevalence
- Concentration

- Fit full, null and restricted model.
- Do checks on restricted models.

Generate a compliance categorical (Not victimised, victimised but not complied, complied)

```{r compliance-categorical}

case_compliance <- function(x, y){
    a <- case_when(
        x == 0          ~ "Not victim",
        x > 0 & y == 0  ~ "Victim, not comp.",
        y > 0           ~ "Complied"
    )
    factor(a, levels = c("Not victim", "Victim, not comp.", "Complied"))
}

enve_lag_nm_sem1 %>%
    mutate(
        lag_comp_cat = case_compliance(lag_extincs, lag_complied),
        lag_rmt_comp_cat = case_compliance(lag_remote, lag_comp_remote),
        lag_inp_comp_cat = case_compliance(lag_inperson, lag_comp_inperson)
    ) -> enve_lag_nm_sem1

enve_lag_nm_sem1 %$%
    table(lag_comp_cat)

enve_lag_nm_sem1 %$%
    table(lag_rmt_comp_cat)

enve_lag_nm_sem1 %$%
    table(lag_inp_comp_cat)

```

Also generate a numerical variable adjusting the lag value.

```{r lag-cap-adjusted}

enve_lag_nm_sem1 %>%
    mutate(
        lag_extincs_adj = capadjust(lag_extincs, extincs, 7),
        lag_rmt_adj = capadjust(lag_remote, extincs + lag_extincs - lag_remote, 7),
        lag_inp_adj = capadjust(lag_inperson, extincs + lag_extincs - lag_inperson, 7)
    ) -> enve_lag_nm_sem1


enve_lag_nm_sem1 %$%
    table(lag_extincs_adj, useNA = "ifany")

enve_lag_nm_sem1 %$%
    table(lag_rmt_adj, useNA = "ifany")

enve_lag_nm_sem1 %$%
    table(lag_inp_adj, useNA = "ifany")


enve_lag_nm_sem1 %$%
    anyNA(lag_rmt_adj)

enve_lag_nm_sem1 %$%
    anyNA(lag_inp_adj)

enve_lag_nm_sem1 %>%
    drop_na -> enve_lag_nm_sem1_nona

nrow(enve_lag_nm_sem1)
nrow(enve_lag_nm_sem1_nona)


```

EDA of the new variables

```{r eda-comp-cats}


comp_cat_extincs_eda <- tableby(mkbin(extincs) ~ lag_comp_cat,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(comp_cat_extincs_eda,
            pfootnote = TRUE)

# Repeat extortions

comp_cat_extincs_eda_r <- tableby(mkbin(extincs, 1) ~ lag_comp_cat,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(comp_cat_extincs_eda_r,
            pfootnote = TRUE)

# remote extortions

comp_cat_rmt_eda <- tableby(mkbin(remote) ~ lag_rmt_comp_cat,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(comp_cat_rmt_eda,
            pfootnote = TRUE)

# repeat remote extortions

comp_cat_rmt_eda_r <- tableby(mkbin(remote, 1) ~ lag_rmt_comp_cat,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(comp_cat_rmt_eda_r,
            pfootnote = TRUE)


# inperson extortions

comp_cat_inp_eda <- tableby(mkbin(inperson) ~ lag_inp_comp_cat,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(comp_cat_inp_eda,
            pfootnote = TRUE)

# repeat inperson extortions

comp_cat_inp_eda_r <- tableby(mkbin(inperson, 1) ~ lag_inp_comp_cat,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(comp_cat_inp_eda_r,
            pfootnote = TRUE)




```

```{r eda-adj-lag}


adj_lag_extincs_eda <- tableby(mkbin(extincs) ~ lag_extincs_adj,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(adj_lag_extincs_eda,
            pfootnote = TRUE)

# Repeat extortions

adj_lag_extincs_eda_r <- tableby(mkbin(extincs, 1) ~ lag_extincs_adj,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(adj_lag_extincs_eda_r,
            pfootnote = TRUE)

# remote extortions

adj_lag_rmt_eda <- tableby(mkbin(remote) ~ lag_rmt_adj,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(adj_lag_rmt_eda,
            pfootnote = TRUE)

# repeat remote extortions

adj_lag_rmt_eda_r <- tableby(mkbin(remote, 1) ~ lag_rmt_adj,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(adj_lag_rmt_eda_r,
            pfootnote = TRUE)


# inperson extortions

adj_lag_inp_eda <- tableby(mkbin(inperson) ~ lag_inp_adj,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(adj_lag_inp_eda,
            pfootnote = TRUE)

# repeat inperson extortions

adj_lag_inp_eda_r <- tableby(mkbin(inperson, 1) ~ lag_inp_adj,
                        data  = enve_lag_nm_sem1_nona,
                        control = my_controls)

summary(adj_lag_inp_eda_r,
            pfootnote = TRUE)




```


#### Remote

Model event dependence on remote extortions.

Do only prevalence (logit) and concentration (truncated count) models.


```{r remote-event-dependence-prevalence}

## Use enve_lag_nm_sem1_nona

# Bivariate model of event dependence

ed_rmt_logit <- glmmTMB(mkbin(remote) ~ lag_remote,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_rmt_logit)

# Test multilevel

ed_rmt_mlogit <- update(ed_rmt_logit, add_nom)

countsummary(ed_rmt_mlogit)

compare_nested(ed_rmt_logit, ed_rmt_mlogit)

## null models

ed_rmt_mlogit_null <- update(ed_rmt_mlogit, . ~ . - lag_remote)

summary(ed_rmt_mlogit_null)

### Risk heterogeneity

ed_rmt_mlogit_risk <- update(ed_rmt_mlogit, formula(rmt_mlogit_pars))

countsummary(ed_rmt_mlogit_risk)

#### add lag to risk

ed_rmt_mlogit_risk_lag <- update(ed_rmt_mlogit_risk,
            . ~ lag_remote + .)

countsummary(ed_rmt_mlogit_risk_lag)


### Test multilevel

ed_rmt_logit_risk_lag <- update(ed_rmt_mlogit_risk_lag,
            . ~ . - (1|NOM_ENT))

countsummary(ed_rmt_logit_risk_lag)

compare_nested(ed_rmt_logit_risk_lag, ed_rmt_mlogit_risk_lag)

#### Risk to lag

compare_nested(ed_rmt_mlogit_risk, ed_rmt_mlogit_risk_lag)

#### Lag to risk

compare_nested(ed_rmt_mlogit, ed_rmt_mlogit_risk_lag)

coef_csv(ed_rmt_mlogit)
coef_csv(ed_rmt_mlogit_risk)
coef_csv(ed_rmt_mlogit_risk_lag)

## Then lag_rmt_adj

# Bivariate model of event dependence

ed_rmt_logit_adj <- glmmTMB(mkbin(remote) ~ lag_rmt_adj,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_rmt_logit_adj)

# Test multilevel

ed_rmt_mlogit_adj <- update(ed_rmt_logit_adj, add_nom)

countsummary(ed_rmt_mlogit_adj)

compare_nested(ed_rmt_logit_adj, ed_rmt_mlogit_adj)

AICtab(ed_rmt_mlogit_adj, ed_rmt_mlogit)

#### add adj lag

ed_rmt_mlogit_risk_lag_adj <- update(ed_rmt_mlogit_risk,
            . ~ lag_rmt_adj + .)

countsummary(ed_rmt_mlogit_risk_lag_adj)


### Test multilevel

ed_rmt_logit_risk_lag_adj <- update(ed_rmt_mlogit_risk_lag_adj,
            . ~ . - (1|NOM_ENT))

countsummary(ed_rmt_logit_risk_lag_adj)

compare_nested(ed_rmt_logit_risk_lag_adj, ed_rmt_mlogit_risk_lag_adj)

#### Risk to lag

compare_nested(ed_rmt_mlogit_risk, ed_rmt_mlogit_risk_lag_adj)

#### Lag to risk

compare_nested(ed_rmt_mlogit_adj, ed_rmt_mlogit_risk_lag_adj)

coef_csv(ed_rmt_mlogit_adj)
coef_csv(ed_rmt_mlogit_risk_lag_adj)

## then lag_rmt_comp_cat

# Bivariate model of event dependence

ed_rmt_logit_comp <- glmmTMB(mkbin(remote) ~ lag_rmt_comp_cat,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_rmt_logit_comp)

# Test multilevel

ed_rmt_mlogit_comp <- update(ed_rmt_logit_comp, add_nom)

countsummary(ed_rmt_mlogit_comp)

compare_nested(ed_rmt_logit_comp, ed_rmt_mlogit_comp)

AICtab(ed_rmt_mlogit_comp, ed_rmt_mlogit_adj, ed_rmt_mlogit)

#### add comp lag to risk

ed_rmt_mlogit_risk_lag_comp <- update(ed_rmt_mlogit_risk,
            . ~ lag_rmt_comp_cat + .)

countsummary(ed_rmt_mlogit_risk_lag_comp)


### Test multilevel

ed_rmt_logit_risk_lag_comp <- update(ed_rmt_mlogit_risk_lag_comp,
            . ~ . - (1|NOM_ENT))

countsummary(ed_rmt_logit_risk_lag_comp)

compare_nested(ed_rmt_logit_risk_lag_comp,
                ed_rmt_mlogit_risk_lag_comp)

#### Risk to lag

compare_nested(ed_rmt_mlogit_risk, ed_rmt_mlogit_risk_lag_comp)

#### Lag to risk

compare_nested(ed_rmt_mlogit_comp, ed_rmt_mlogit_risk_lag_comp)

coef_csv(ed_rmt_mlogit_comp)
coef_csv(ed_rmt_mlogit_risk_lag_comp)


```


Next, estimate the effect of event dependence on concentration.

Begin with Poisson, (nb may be significant).
Mutilevel not significant
Use ADMB
It appears only size is significant risk factor.

```{r remote-event-dependence-concentration}

## Use enve_lag_nm_sem1

ed_rmt_tp <- glmmadmb(remote ~ lag_remote,
     data = subset(enve_lag_nm_sem1_nona, remote > 0),
     family = "truncpoiss",
     zeroInflation = FALSE,
     admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE),
     extra.args = "-ndi 60000")

countsummary(ed_rmt_tp)

## Is nb significant?

ed_rmt_tnb <- update(ed_rmt_tp, family = "truncnbinom")

countsummary(ed_rmt_tnb)

compare_nested(ed_rmt_tp, ed_rmt_tnb)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_rmt_mtp <- update(ed_rmt_tp, add_nom)

countsummary(ed_rmt_mtp)

compare_nested(ed_rmt_tp, ed_rmt_mtp)

#negbin
ed_rmt_mtnb <- update(ed_rmt_tnb, add_nom)

countsummary(ed_rmt_mtnb)

compare_nested(ed_rmt_tnb, ed_rmt_mtnb)

compare_nested(ed_rmt_mtp, ed_rmt_mtnb)

### add risk heterogeneity: previous indicate only size is significant (also maybe subsector, drogas and general)

# compare to risk factors for prevalence

rmt_prv_risk <- update(formula(ed_rmt_mlogit_risk),
                    remote ~ . - (1|NOM_ENT))

ed_rmt_tp_risk_full <- update(ed_rmt_tp, rmt_prv_risk)

countsummary(ed_rmt_tp_risk_full)

## compare to previous results (only size sig)

ed_rmt_tp_risk_pars <- update(ed_rmt_tp, . ~ + size)

countsummary(ed_rmt_tp_risk_pars)

compare_nested(ed_rmt_tp_risk_pars, ed_rmt_tp_risk_full)

# nb

ed_rmt_tnb_risk_full <- update(ed_rmt_tp_risk_full,
                    family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_full)

compare_nested(ed_rmt_tp_risk_full, ed_rmt_tnb_risk_full)

ed_rmt_tnb_risk_pars <- update(ed_rmt_tp_risk_pars,
                    family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_pars)

compare_nested(ed_rmt_tp_risk_pars, ed_rmt_tnb_risk_pars)
compare_nested(ed_rmt_tnb_risk_pars, ed_rmt_tnb_risk_full)

## multilevel

ed_rmt_mtp_risk_full <- update(ed_rmt_tp_risk_full, add_nom)

countsummary(ed_rmt_mtp_risk_full)

compare_nested(ed_rmt_tp_risk_full, ed_rmt_mtp_risk_full)

## compare to previous results (only size sig)

ed_rmt_mtp_risk_pars <- update(ed_rmt_mtp, . ~ + size)

countsummary(ed_rmt_mtp_risk_pars)

compare_nested(ed_rmt_tp_risk_pars, ed_rmt_mtp_risk_pars)
compare_nested(ed_rmt_mtp_risk_pars, ed_rmt_mtp_risk_full)

# nb

ed_rmt_mtnb_risk_full <- update(ed_rmt_mtp_risk_full,
                    family = "truncnbinom")

countsummary(ed_rmt_mtnb_risk_full)

compare_nested(ed_rmt_tnb_risk_full, ed_rmt_mtnb_risk_full)
compare_nested(ed_rmt_mtp_risk_full, ed_rmt_mtnb_risk_full)

ed_rmt_mtnb_risk_pars <- update(ed_rmt_mtp_risk_pars,
                    family = "truncnbinom")

countsummary(ed_rmt_mtnb_risk_pars)

compare_nested(ed_rmt_tnb_risk_pars, ed_rmt_mtnb_risk_pars)
compare_nested(ed_rmt_mtp_risk_pars, ed_rmt_mtnb_risk_pars)
compare_nested(ed_rmt_mtnb_risk_pars, ed_rmt_mtnb_risk_full)

## adding lag to risk model
ed_rmt_tp_risk_pars_lag <- update(ed_rmt_tp_risk_pars,
                        . ~ lag_remote + .)

countsummary(ed_rmt_tp_risk_pars_lag)

ed_rmt_tp_risk_lag <- update(ed_rmt_tp_risk_full,
                        . ~ lag_remote + .)

countsummary(ed_rmt_tp_risk_lag)

compare_nested(ed_rmt_tp_risk_pars_lag, ed_rmt_tp_risk_lag)

### nb

ed_rmt_tnb_risk_pars_lag <- update(ed_rmt_tp_risk_pars_lag,
                        family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_pars_lag)

compare_nested(ed_rmt_tp_risk_pars_lag, ed_rmt_tnb_risk_pars_lag)

ed_rmt_tnb_risk_lag <- update(ed_rmt_tp_risk_lag,
                        family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_lag)

compare_nested(ed_rmt_tp_risk_lag, ed_rmt_tnb_risk_lag)

compare_nested(ed_rmt_tnb_risk_pars_lag, ed_rmt_tnb_risk_lag)

### multilevel

ed_rmt_mtp_risk_pars_lag <- update(ed_rmt_tp_risk_pars_lag,
                        add_nom)

countsummary(ed_rmt_mtp_risk_pars_lag)

compare_nested(ed_rmt_tp_risk_pars_lag, ed_rmt_mtp_risk_pars_lag)

ed_rmt_mtp_risk_lag <- update(ed_rmt_tp_risk_lag,
                        add_nom)

countsummary(ed_rmt_mtp_risk_lag)

compare_nested(ed_rmt_tp_risk_lag, ed_rmt_mtp_risk_lag)

compare_nested(ed_rmt_mtp_risk_pars_lag, ed_rmt_mtp_risk_lag)

### mtnb

ed_rmt_mtnb_risk_pars_lag <- update(ed_rmt_tnb_risk_pars_lag,
                        add_nom)

countsummary(ed_rmt_mtnb_risk_pars_lag)

compare_nested(ed_rmt_tnb_risk_pars_lag, ed_rmt_mtnb_risk_pars_lag)

compare_nested(ed_rmt_mtp_risk_pars_lag, ed_rmt_mtnb_risk_pars_lag)

ed_rmt_mtnb_risk_lag <- update(ed_rmt_tnb_risk_lag,
                        add_nom)

countsummary(ed_rmt_mtnb_risk_lag)

compare_nested(ed_rmt_tnb_risk_lag, ed_rmt_mtnb_risk_lag)

compare_nested(ed_rmt_mtp_risk_lag, ed_rmt_mtnb_risk_lag)

compare_nested(ed_rmt_mtnb_risk_pars_lag, ed_rmt_mtnb_risk_lag)


## significance of risk to lag

compare_nested(ed_rmt_tp, ed_rmt_tp_risk_lag)
compare_nested(ed_rmt_tp, ed_rmt_tp_risk_pars_lag)

compare_nested(ed_rmt_tnb, ed_rmt_tnb_risk_lag)
compare_nested(ed_rmt_tnb, ed_rmt_tnb_risk_pars_lag)

compare_nested(ed_rmt_mtp, ed_rmt_mtp_risk_lag)
compare_nested(ed_rmt_mtp, ed_rmt_mtp_risk_pars_lag)

compare_nested(ed_rmt_mtnb, ed_rmt_mtnb_risk_lag)
compare_nested(ed_rmt_mtnb, ed_rmt_mtnb_risk_pars_lag)

## significance of lag to risk

compare_nested(ed_rmt_tp_risk_full, ed_rmt_tp_risk_lag)
compare_nested(ed_rmt_tp_risk_pars, ed_rmt_tp_risk_pars_lag)

compare_nested(ed_rmt_tnb_risk_full, ed_rmt_tnb_risk_lag)
compare_nested(ed_rmt_tnb_risk_pars, ed_rmt_tnb_risk_pars_lag)

compare_nested(ed_rmt_mtp_risk_full, ed_rmt_mtp_risk_lag)
compare_nested(ed_rmt_mtp_risk_pars, ed_rmt_mtp_risk_pars_lag)

compare_nested(ed_rmt_mtnb_risk_full, ed_rmt_mtnb_risk_lag)
compare_nested(ed_rmt_mtnb_risk_pars, ed_rmt_mtnb_risk_pars_lag)

## save as csv

coef_csv(ed_rmt_tp)
coef_csv(ed_rmt_tp_risk_lag)
coef_csv(ed_rmt_tp_risk_pars_lag)

coef_csv(ed_rmt_tnb)
coef_csv(ed_rmt_tnb_risk_lag)
coef_csv(ed_rmt_tnb_risk_pars_lag)

coef_csv(ed_rmt_mtp)
coef_csv(ed_rmt_mtp_risk_lag)
coef_csv(ed_rmt_mtp_risk_pars_lag)

coef_csv(ed_rmt_mtnb)
coef_csv(ed_rmt_mtnb_risk_lag)
coef_csv(ed_rmt_mtnb_risk_pars_lag)

## repeat for adjusted lag

ed_rmt_tp_adj <- update(ed_rmt_tp, . ~ lag_rmt_adj)

countsummary(ed_rmt_tp_adj)
AICtab(ed_rmt_tp_adj, ed_rmt_tp)

## Is nb significant?

ed_rmt_tnb_adj <- update(ed_rmt_tp_adj, family = "truncnbinom")

countsummary(ed_rmt_tnb_adj)

compare_nested(ed_rmt_tp_adj, ed_rmt_tnb_adj)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_rmt_mtp_adj <- update(ed_rmt_tp_adj, add_nom)

countsummary(ed_rmt_mtp_adj)

compare_nested(ed_rmt_tp_adj, ed_rmt_mtp_adj)

#negbin
ed_rmt_mtnb_adj <- update(ed_rmt_tnb_adj, add_nom)

countsummary(ed_rmt_mtnb_adj)

compare_nested(ed_rmt_tnb_adj, ed_rmt_mtnb_adj)

compare_nested(ed_rmt_mtp_adj, ed_rmt_mtnb_adj)


## adding lag to risk model
ed_rmt_tp_risk_pars_lag_adj <- update(ed_rmt_tp_risk_pars,
                        . ~ lag_rmt_adj + .)

countsummary(ed_rmt_tp_risk_pars_lag_adj)

ed_rmt_tp_risk_lag_adj <- update(ed_rmt_tp_risk_full,
                        . ~ lag_rmt_adj + .)

countsummary(ed_rmt_tp_risk_lag_adj)

compare_nested(ed_rmt_tp_risk_pars_lag_adj, ed_rmt_tp_risk_lag_adj)

### nb

ed_rmt_tnb_risk_pars_lag_adj <- update(ed_rmt_tp_risk_pars_lag_adj,
                        family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_pars_lag_adj)

compare_nested(ed_rmt_tp_risk_pars_lag_adj, ed_rmt_tnb_risk_pars_lag_adj)

ed_rmt_tnb_risk_lag_adj <- update(ed_rmt_tp_risk_lag_adj,
                        family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_lag_adj)

compare_nested(ed_rmt_tp_risk_lag_adj, ed_rmt_tnb_risk_lag_adj)

compare_nested(ed_rmt_tnb_risk_pars_lag_adj, ed_rmt_tnb_risk_lag_adj)

### multilevel

ed_rmt_mtp_risk_pars_lag_adj <- update(ed_rmt_tp_risk_pars_lag_adj,
                        add_nom)

countsummary(ed_rmt_mtp_risk_pars_lag_adj)

compare_nested(ed_rmt_tp_risk_pars_lag_adj, ed_rmt_mtp_risk_pars_lag_adj)

ed_rmt_mtp_risk_lag_adj <- update(ed_rmt_tp_risk_lag_adj,
                        add_nom)

countsummary(ed_rmt_mtp_risk_lag_adj)

compare_nested(ed_rmt_tp_risk_lag_adj, ed_rmt_mtp_risk_lag_adj)

compare_nested(ed_rmt_mtp_risk_pars_lag_adj, ed_rmt_mtp_risk_lag_adj)

### mtnb

ed_rmt_mtnb_risk_pars_lag_adj <- update(ed_rmt_tnb_risk_pars_lag_adj,
                        add_nom)

countsummary(ed_rmt_mtnb_risk_pars_lag_adj)

compare_nested(ed_rmt_tnb_risk_pars_lag_adj, ed_rmt_mtnb_risk_pars_lag_adj)

compare_nested(ed_rmt_mtp_risk_pars_lag_adj, ed_rmt_mtnb_risk_pars_lag_adj)

ed_rmt_mtnb_risk_lag_adj <- update(ed_rmt_tnb_risk_lag_adj,
                        add_nom)

countsummary(ed_rmt_mtnb_risk_lag_adj)

compare_nested(ed_rmt_tnb_risk_lag_adj, ed_rmt_mtnb_risk_lag_adj)

compare_nested(ed_rmt_mtp_risk_lag_adj, ed_rmt_mtnb_risk_lag_adj)

compare_nested(ed_rmt_mtnb_risk_pars_lag_adj, ed_rmt_mtnb_risk_lag_adj)


## significance of risk to lag

compare_nested(ed_rmt_tp_adj, ed_rmt_tp_risk_lag_adj)
compare_nested(ed_rmt_tp_adj, ed_rmt_tp_risk_pars_lag_adj)

compare_nested(ed_rmt_tnb_adj, ed_rmt_tnb_risk_lag_adj)
compare_nested(ed_rmt_tnb_adj, ed_rmt_tnb_risk_pars_lag_adj)

compare_nested(ed_rmt_mtp_adj, ed_rmt_mtp_risk_lag_adj)
compare_nested(ed_rmt_mtp_adj, ed_rmt_mtp_risk_pars_lag_adj)

compare_nested(ed_rmt_mtnb_adj, ed_rmt_mtnb_risk_lag_adj)
compare_nested(ed_rmt_mtnb_adj, ed_rmt_mtnb_risk_pars_lag_adj)

## significance of lag to risk

compare_nested(ed_rmt_tp_risk_full, ed_rmt_tp_risk_lag_adj)
compare_nested(ed_rmt_tp_risk_pars, ed_rmt_tp_risk_pars_lag_adj)

compare_nested(ed_rmt_tnb_risk_full, ed_rmt_tnb_risk_lag_adj)
compare_nested(ed_rmt_tnb_risk_pars, ed_rmt_tnb_risk_pars_lag_adj)

compare_nested(ed_rmt_mtp_risk_full, ed_rmt_mtp_risk_lag_adj)
compare_nested(ed_rmt_mtp_risk_pars, ed_rmt_mtp_risk_pars_lag_adj)

compare_nested(ed_rmt_mtnb_risk_full, ed_rmt_mtnb_risk_lag_adj)
compare_nested(ed_rmt_mtnb_risk_pars, ed_rmt_mtnb_risk_pars_lag_adj)

## save as csv

coef_csv(ed_rmt_tp_adj)
coef_csv(ed_rmt_tp_risk_lag_adj)
coef_csv(ed_rmt_tp_risk_pars_lag_adj)

coef_csv(ed_rmt_tnb_adj)
coef_csv(ed_rmt_tnb_risk_lag_adj)
coef_csv(ed_rmt_tnb_risk_pars_lag_adj)

coef_csv(ed_rmt_mtp_adj)
coef_csv(ed_rmt_mtp_risk_lag_adj)
coef_csv(ed_rmt_mtp_risk_pars_lag_adj)

coef_csv(ed_rmt_mtnb_adj)
coef_csv(ed_rmt_mtnb_risk_lag_adj)
coef_csv(ed_rmt_mtnb_risk_pars_lag_adj)


## repeat for comp lag categories

ed_rmt_tp_comp <- update(ed_rmt_tp, . ~ lag_rmt_comp_cat)

countsummary(ed_rmt_tp_comp)
AICtab(ed_rmt_tp_comp, ed_rmt_tp_adj, ed_rmt_tp)

## Is nb significant?

ed_rmt_tnb_comp <- update(ed_rmt_tp_comp, family = "truncnbinom")

countsummary(ed_rmt_tnb_comp)

compare_nested(ed_rmt_tp_comp, ed_rmt_tnb_comp)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_rmt_mtp_comp <- update(ed_rmt_tp_comp, add_nom)

countsummary(ed_rmt_mtp_comp)

compare_nested(ed_rmt_tp_comp, ed_rmt_mtp_comp)

#negbin
ed_rmt_mtnb_comp <- update(ed_rmt_tnb_comp, add_nom)

countsummary(ed_rmt_mtnb_comp)

compare_nested(ed_rmt_tnb_comp, ed_rmt_mtnb_comp)

compare_nested(ed_rmt_mtp_comp, ed_rmt_mtnb_comp)


## adding lag to risk model
ed_rmt_tp_risk_pars_lag_comp <- update(ed_rmt_tp_risk_pars,
                        . ~ lag_rmt_comp_cat + .)

countsummary(ed_rmt_tp_risk_pars_lag_comp)

ed_rmt_tp_risk_lag_comp <- update(ed_rmt_tp_risk_full,
                        . ~ lag_rmt_comp_cat + .)

countsummary(ed_rmt_tp_risk_lag_comp)

compare_nested(ed_rmt_tp_risk_pars_lag_comp, ed_rmt_tp_risk_lag_comp)

### nb

ed_rmt_tnb_risk_pars_lag_comp <- update(ed_rmt_tp_risk_pars_lag_comp,
                        family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_pars_lag_comp)

compare_nested(ed_rmt_tp_risk_pars_lag_comp, ed_rmt_tnb_risk_pars_lag_comp)

ed_rmt_tnb_risk_lag_comp <- update(ed_rmt_tp_risk_lag_comp,
                        family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_lag_comp)

compare_nested(ed_rmt_tp_risk_lag_comp, ed_rmt_tnb_risk_lag_comp)

compare_nested(ed_rmt_tnb_risk_pars_lag_comp, ed_rmt_tnb_risk_lag_comp)

### multilevel

ed_rmt_mtp_risk_pars_lag_comp <- update(ed_rmt_tp_risk_pars_lag_comp,
                        add_nom)

countsummary(ed_rmt_mtp_risk_pars_lag_comp)

compare_nested(ed_rmt_tp_risk_pars_lag_comp, ed_rmt_mtp_risk_pars_lag_comp)

ed_rmt_mtp_risk_lag_comp <- update(ed_rmt_tp_risk_lag_comp,
                        add_nom)

countsummary(ed_rmt_mtp_risk_lag_comp)

compare_nested(ed_rmt_tp_risk_lag_comp, ed_rmt_mtp_risk_lag_comp)

compare_nested(ed_rmt_mtp_risk_pars_lag_comp, ed_rmt_mtp_risk_lag_comp)

### mtnb

ed_rmt_mtnb_risk_pars_lag_comp <- update(ed_rmt_tnb_risk_pars_lag_comp,
                        add_nom)

countsummary(ed_rmt_mtnb_risk_pars_lag_comp)

compare_nested(ed_rmt_tnb_risk_pars_lag_comp, ed_rmt_mtnb_risk_pars_lag_comp)

compare_nested(ed_rmt_mtp_risk_pars_lag_comp, ed_rmt_mtnb_risk_pars_lag_comp)

ed_rmt_mtnb_risk_lag_comp <- update(ed_rmt_tnb_risk_lag_comp,
                        add_nom)

countsummary(ed_rmt_mtnb_risk_lag_comp)

compare_nested(ed_rmt_tnb_risk_lag_comp, ed_rmt_mtnb_risk_lag_comp)

compare_nested(ed_rmt_mtp_risk_lag_comp, ed_rmt_mtnb_risk_lag_comp)

compare_nested(ed_rmt_mtnb_risk_pars_lag_comp, ed_rmt_mtnb_risk_lag_comp)


## significance of risk to lag

compare_nested(ed_rmt_tp_comp, ed_rmt_tp_risk_lag_comp)
compare_nested(ed_rmt_tp_comp, ed_rmt_tp_risk_pars_lag_comp)

compare_nested(ed_rmt_tnb_comp, ed_rmt_tnb_risk_lag_comp)
compare_nested(ed_rmt_tnb_comp, ed_rmt_tnb_risk_pars_lag_comp)

compare_nested(ed_rmt_mtp_comp, ed_rmt_mtp_risk_lag_comp)
compare_nested(ed_rmt_mtp_comp, ed_rmt_mtp_risk_pars_lag_comp)

compare_nested(ed_rmt_mtnb_comp, ed_rmt_mtnb_risk_lag_comp)
compare_nested(ed_rmt_mtnb_comp, ed_rmt_mtnb_risk_pars_lag_comp)

## significance of lag to risk

compare_nested(ed_rmt_tp_risk_full, ed_rmt_tp_risk_lag_comp)
compare_nested(ed_rmt_tp_risk_pars, ed_rmt_tp_risk_pars_lag_comp)

compare_nested(ed_rmt_tnb_risk_full, ed_rmt_tnb_risk_lag_comp)
compare_nested(ed_rmt_tnb_risk_pars, ed_rmt_tnb_risk_pars_lag_comp)

compare_nested(ed_rmt_mtp_risk_full, ed_rmt_mtp_risk_lag_comp)
compare_nested(ed_rmt_mtp_risk_pars, ed_rmt_mtp_risk_pars_lag_comp)

compare_nested(ed_rmt_mtnb_risk_full, ed_rmt_mtnb_risk_lag_comp)
compare_nested(ed_rmt_mtnb_risk_pars, ed_rmt_mtnb_risk_pars_lag_comp)

## save as csv

coef_csv(ed_rmt_tp_comp)
coef_csv(ed_rmt_tp_risk_lag_comp)
coef_csv(ed_rmt_tp_risk_pars_lag_comp)

coef_csv(ed_rmt_tnb_comp)
coef_csv(ed_rmt_tnb_risk_lag_comp)
coef_csv(ed_rmt_tnb_risk_pars_lag_comp)

coef_csv(ed_rmt_mtp_comp)
coef_csv(ed_rmt_mtp_risk_lag_comp)
coef_csv(ed_rmt_mtp_risk_pars_lag_comp)

coef_csv(ed_rmt_mtnb_comp)
coef_csv(ed_rmt_mtnb_risk_lag_comp)
coef_csv(ed_rmt_mtnb_risk_pars_lag_comp)


```

Next, in person.

#### In person

Repeat for in-person

Prevalence models

```{r inperson-event-dependence-prevalence}


## Use enve_lag_nm_sem1_nona

# Bivariate model of event dependence

ed_inp_logit <- glmmTMB(mkbin(inperson) ~ lag_inperson,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_inp_logit)

# Test multilevel

ed_inp_mlogit <- update(ed_inp_logit, add_nom)

countsummary(ed_inp_mlogit)

compare_nested(ed_inp_logit, ed_inp_mlogit)

## null models

ed_inp_mlogit_null <- update(ed_inp_mlogit, . ~ . - lag_inperson)

summary(ed_inp_mlogit_null)

### Risk heterogeneity

inp_preval_risk_f <- update(formula(inp_mlogit_pars_95),
                mkbin(inperson) ~ .)

ed_inp_mlogit_risk <- update(ed_inp_mlogit, inp_preval_risk_f)

countsummary(ed_inp_mlogit_risk)

## test polybribes?

ed_inp_mlogit_risk_b <- update(ed_inp_mlogit_risk,
                . ~ bribes + . - poly(bribes, 2, raw = TRUE))


countsummary(ed_inp_mlogit_risk_b)

compare_nested(ed_inp_mlogit_risk_b, ed_inp_mlogit_risk)

best_model <- function(m1, m2){
    aic_m1 <- AIC(m1)
    aic_m2 <- AIC(m2)

    m1_better <- aic_m1 < aic_m2

    if(m1_better){
        best_model <- m1
        mod_name <- deparse(substitute(m1))
    } else{
        best_model <- m2
        mod_name <- deparse(substitute(m2))
    }
    message(paste0("\n", mod_name, " is better.\n"))
    return(best_model)
}

ed_inp_mlogit_best_risk <- best_model(ed_inp_mlogit_risk, ed_inp_mlogit_risk_b)

#### add lag to risk

ed_inp_mlogit_risk_lag <- update(ed_inp_mlogit_best_risk,
            . ~ lag_inperson + .)

countsummary(ed_inp_mlogit_risk_lag)


### Test multilevel

ed_inp_logit_risk_lag <- update(ed_inp_mlogit_risk_lag,
            . ~ . - (1|NOM_ENT))

countsummary(ed_inp_logit_risk_lag)

compare_nested(ed_inp_logit_risk_lag, ed_inp_mlogit_risk_lag)

#### Risk to lag

compare_nested(ed_inp_mlogit_best_risk, ed_inp_mlogit_risk_lag)

#### Lag to risk

compare_nested(ed_inp_mlogit, ed_inp_mlogit_risk_lag)

coef_csv(ed_inp_mlogit)
coef_csv(ed_inp_mlogit_best_risk)
coef_csv(ed_inp_mlogit_risk_lag)

## Then lag_rmt_adj

# Bivariate model of event dependence

ed_inp_logit_adj <- glmmTMB(mkbin(inperson) ~ lag_inp_adj,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_inp_logit_adj)

# Test multilevel

ed_inp_mlogit_adj <- update(ed_inp_logit_adj, add_nom)

countsummary(ed_inp_mlogit_adj)

compare_nested(ed_inp_logit_adj, ed_inp_mlogit_adj)

AICtab(ed_inp_mlogit_adj, ed_inp_mlogit)

#### add adj lag

ed_inp_mlogit_risk_lag_adj <- update(ed_inp_mlogit_best_risk,
            . ~ lag_inp_adj + .)

countsummary(ed_inp_mlogit_risk_lag_adj)


### Test multilevel

ed_inp_logit_risk_lag_adj <- update(ed_inp_mlogit_risk_lag_adj,
            . ~ . - (1|NOM_ENT))

countsummary(ed_inp_logit_risk_lag_adj)

compare_nested(ed_inp_logit_risk_lag_adj, ed_inp_mlogit_risk_lag_adj)

#### Risk to lag

compare_nested(ed_inp_mlogit_risk, ed_inp_mlogit_risk_lag_adj)

#### Lag to risk

compare_nested(ed_inp_mlogit_adj, ed_inp_mlogit_risk_lag_adj)

coef_csv(ed_inp_mlogit_adj)
coef_csv(ed_inp_mlogit_risk_lag_adj)

## then lag_inp_comp_cat

# Bivariate model of event dependence

ed_inp_logit_comp <- glmmTMB(mkbin(remote) ~ lag_inp_comp_cat,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_inp_logit_comp)

# Test multilevel

ed_inp_mlogit_comp <- update(ed_inp_logit_comp, add_nom)

countsummary(ed_inp_mlogit_comp)

compare_nested(ed_inp_logit_comp, ed_inp_mlogit_comp)

AICtab(ed_inp_mlogit_comp, ed_inp_mlogit_adj, ed_inp_mlogit)

#### add comp lag to risk

ed_inp_mlogit_risk_lag_comp <- update(ed_inp_mlogit_best_risk,
            . ~ lag_inp_comp_cat + .)

countsummary(ed_inp_mlogit_risk_lag_comp)


### Test multilevel

ed_inp_logit_risk_lag_comp <- update(ed_inp_mlogit_risk_lag_comp,
            . ~ . - (1|NOM_ENT))

countsummary(ed_inp_logit_risk_lag_comp)

compare_nested(ed_inp_logit_risk_lag_comp,
                ed_inp_mlogit_risk_lag_comp)

#### Risk to lag

compare_nested(ed_inp_mlogit_risk, ed_inp_mlogit_risk_lag_comp)

#### Lag to risk

compare_nested(ed_inp_mlogit_comp, ed_inp_mlogit_risk_lag_comp)

coef_csv(ed_inp_mlogit_comp)
coef_csv(ed_inp_mlogit_risk_lag_comp)


```


Next, estimate the effect of event dependence in the truncated count.

```{r inperson-event-dependence-concentration}


## Use enve_lag_nm_sem1

ed_inp_tp <- glmmadmb(inperson ~ lag_inperson,
     data = subset(enve_lag_nm_sem1_nona, inperson > 0),
     family = "truncpoiss",
     zeroInflation = FALSE,
     admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE),
     extra.args = "-ndi 60000")

countsummary(ed_inp_tp)

## Is nb significant?

ed_inp_tnb <- update(ed_inp_tp, family = "truncnbinom")

countsummary(ed_inp_tnb)

compare_nested(ed_inp_tp, ed_inp_tnb)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_inp_mtp <- update(ed_inp_tp, add_nom)

countsummary(ed_inp_mtp)

compare_nested(ed_inp_tp, ed_inp_mtp)



### add risk heterogeneity: previous indicate only ROL might be significant. Use the risk factors for prevalence to compare

# compare to risk factors for prevalence

inp_prv_risk <- update(formula(ed_inp_mlogit_best_risk),
                    inperson ~ . - (1|NOM_ENT))

ed_inp_tp_risk <- update(ed_inp_tp, inp_prv_risk)

countsummary(ed_inp_tp_risk)

### Add rule of law

ed_inp_tp_risk_rol <- update(ed_inp_tp_risk, . ~ . +
                scale(Derecho, mean_Derecho, FALSE))

countsummary(ed_inp_tp_risk_rol)

ed_inp_tp_rol <- update(ed_inp_tp, . ~
                scale(Derecho, mean_Derecho, FALSE))

countsummary(ed_inp_tp_rol)

compare_nested(ed_inp_tp_risk, ed_inp_tp_risk_rol)

compare_nested(ed_inp_tp_rol, ed_inp_tp_risk_rol)

ed_inp_tp_best_risk <- best_model(ed_inp_tp_risk, ed_inp_tp_risk_rol)

ed_inp_tp_best_risk <- best_model(ed_inp_tp_rol, ed_inp_tp_risk_rol)


## adding lag to risk model
ed_inp_tp_risk_lag <- update(ed_inp_tp_best_risk,
                        . ~ lag_inperson + .)

countsummary(ed_inp_tp_risk_lag)

## significance of risk to lag

compare_nested(ed_inp_tp, ed_inp_tp_risk_lag)

## significance of lag to risk

compare_nested(ed_inp_tp_best_risk, ed_inp_tp_risk_lag)

## save as csv

coef_csv(ed_inp_tp)
coef_csv(ed_inp_tp_risk_lag)
coef_csv(ed_inp_tp_best_risk)

## repeat for adjusted lag

ed_inp_tp_adj <- glmmadmb(inperson ~ lag_inp_adj,
     data = subset(enve_lag_nm_sem1_nona, inperson > 0),
     family = "truncpoiss",
     zeroInflation = FALSE,
     admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE),
     extra.args = "-ndi 60000")

countsummary(ed_inp_tp_adj)

## Is nb significant?

ed_inp_tnb_adj <- update(ed_inp_tp_adj, family = "truncnbinom")

countsummary(ed_inp_tnb_adj)

compare_nested(ed_inp_tp_adj, ed_inp_tnb_adj)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_inp_mtp_adj <- update(ed_inp_tp_adj, add_nom)

countsummary(ed_inp_mtp_adj)

compare_nested(ed_inp_tp_adj, ed_inp_mtp_adj)


### add risk heterogeneity: previous indicate only ROL might be significant. Use the risk factors for prevalence to compare

## adding lag to risk model
ed_inp_tp_risk_lag_adj <- update(ed_inp_tp_best_risk,
                        . ~ lag_inp_adj + .)

countsummary(ed_inp_tp_risk_lag_adj)

## significance of risk to lag

compare_nested(ed_inp_tp_adj, ed_inp_tp_risk_lag_adj)

## significance of lag to risk

compare_nested(ed_inp_tp_best_risk, ed_inp_tp_risk_lag_adj)

## save as csv

coef_csv(ed_inp_tp_adj)
coef_csv(ed_inp_tp_risk_lag_adj)


## repeat for comp lag categories

ed_inp_tp_comp <- glmmadmb(inperson ~ lag_inp_comp_cat,
     data = subset(enve_lag_nm_sem1_nona, inperson > 0),
     family = "truncpoiss",
     zeroInflation = FALSE,
     admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE),
     extra.args = "-ndi 60000")

countsummary(ed_inp_tp_comp)

## Is nb significant?

ed_inp_tnb_comp <- update(ed_inp_tp_comp, family = "truncnbinom")

countsummary(ed_inp_tnb_comp)

compare_nested(ed_inp_tp_comp, ed_inp_tnb_comp)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_inp_mtp_comp <- update(ed_inp_tp_comp, add_nom)

countsummary(ed_inp_mtp_comp)

compare_nested(ed_inp_tp_comp, ed_inp_mtp_comp)


### add risk heterogeneity: previous indicate only ROL might be significant. Use the risk factors for prevalence to compare

## adding lag to risk model
ed_inp_tp_risk_lag_comp <- update(ed_inp_tp_best_risk,
                        . ~ lag_inp_comp_cat + .)

countsummary(ed_inp_tp_risk_lag_comp)

## significance of risk to lag

compare_nested(ed_inp_tp_comp, ed_inp_tp_risk_lag_comp)

## significance of lag to risk

compare_nested(ed_inp_tp_best_risk, ed_inp_tp_risk_lag_comp)

## save as csv

coef_csv(ed_inp_tp_comp)
coef_csv(ed_inp_tp_risk_lag_comp)

```


# Benchmark stats

```{r timing, cache=FALSE}
endtime <- proc.time()
time <- endtime - starttime
time

print(paste("the script took", round(time[3]/60,2),
              "minutes to run.", sep=" "))
```

# References
