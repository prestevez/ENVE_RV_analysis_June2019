---
title: "Extortion concentration patterns: Analysis of event dependence, version 0.4"
author: "Patricio R. Estevez Soto"
email: "patricio.estevez.14@ucl.ac.uk"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  md_document:
    variant: "markdown"
pandoc_args: "--smart"
references:
- id: Estevez-Soto2019
  type: article-journal
  author:
  - family: Estévez-Soto
    given: Patricio R
  - family: Johnson
    given: Shane D
  - family: Tilley
    given: Nick
  issued:
  - year: '2018'
  title: Are repeatedly extorted businesses different? A multilevel hurdle model of extortion victimization
  container-title: Manuscript under review (Submitted Sep. 27, 2018)
- id: Estevez-Soto2019a
  type: article-journal
  author:
  - family: Estévez-Soto
    given: Patricio R
  issued:
  - year: '2019'
  title: |
   Determinants of extortion compliance: Empirical evidence from a victimisation survey
  container-title: Manuscript under review (Submitted June 26, 2019)
- id: Estevez-Soto2019b
  type: article-journal
  author:
  - family: Estévez-Soto
    given: Patricio R
  issued:
  - year: '2019'
  title: |
   Extortion victimisation: A crime specific approach
  container-title: |
   Manuscript in preparation (Version: July 26, 2019)
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      comment="",
                      cache=TRUE,
                      dev=c("png", "CairoPDF"),
                      error=TRUE,
                      fig.width=6, fig.height=5)
options(knitr.kable.NA = '--')
```

This script continues the analysis of the patterns of extortion concentration based on the findings from two previous studies. Using data form a commercial victimisation survey in Mexico, the first study [@Estevez-Soto2019] examined whether the predictors of extortion prevalence were the same as the predictors of extortion concentration using a multilevel negative binomial-logit hurdle model. The study found that the risk factors for extortion prevalence were not the same as those fuelling extortion concentration, possibly due to an unmeasured process of event dependence.

As the likelihood of repeat victimisation is thought to be influenced by how victims respond to a previous event, the second study [@Estevez-Soto2019a] examined the predictors of extortion compliance. Specifically, it sought to answer why most incidents of extortion in Mexico are not complied with. The main hypothesis was that the communication channel used to convey extortion threats was very important in determining compliance, as threats conveyed using lean media (remote extortion) would be less believable than those conveyed using rich media (in-person extortion). The findings suggested that compliance varied widely between remote and in-person extortion, which in turn suggested that extortion analyses should consider these types as different offence classes: the concentration patterns for remote and in-person extortion may be fuelled by different mechanisms.

In the third study [@Estevez-Soto2019b], findings suggested that the victimisation patterns for in-person and remote extortion were indeed fuelled by different opportunity structures (i.e. different risk factors). Furthermore, they also revealed that the factors fuelling the prevalence of victimisation were not the same as those fuelling concentration, which (in my view) could be an implicit sign of event dependence.

Thus, this study aims to explicitly test the role of event dependence in extortion victimisation patterns. The approach involves two analyses. First, the time between repeat events will be analysed to study the time-course of repeat victimisation. This is done to determine if the risks of repeat victimisation follow a risk-decay function as is common in other crime types. Then, the counts of extortion will be classified into two semester terms to facilitate modelling if the prevalence and concentration of extortion in the second semester is associated to extortion victimisation in the previous semester. The analytical approach will be repeated for remote and in-person extortion, as previous studies [@Estevez-Soto2019a; @Estevez-Soto2019b] have shown that these crime types are distinct (as *cobro de piso* showed no repeat incidents, this type of incidents will not be studied here).

Additionally, the models will also incorporate coviariates used in previous studies [@Estevez-Soto2019; @Estevez-Soto2019b], as some of these have been shown to be important factors of risk heterogeneity. however, in this study, these covariates are included only as control variables, thus their effects will not be discussed.

# Set up

To ensure reproducibility and aid in debugging, we first start setting up options and printing the information about the R session.

```{r session, cache=FALSE}
starttime <- proc.time()
date()
sessionInfo()
set.seed(42)
options(scipen=0)

```

Next we load the packages that will be used in the analysis. The installation of these packages should have already been done before. Additionally, we'll import some functions that are required, without importing the entire packages.

```{r packages}
library(victim)
library(tidyverse)
library(downloader)
library(lmtest)
library(magrittr)
library(glmmTMB)
library(lazyeval)
library(glmmADMB)
library(arsenal)
library(bbmle)
library(gridExtra)



read.dbf <- foreign::read.dbf
kable <- knitr::kable
melt <- reshape2::melt
select <- dplyr::select
Anova <- car::Anova
ks.test <- dgof::ks.test



sessionInfo()

# Create csv dir for model results
dir.create("coef_results")

```

Next we load some custom functions. Ideally these should be in a separate stand-alone package, but I have not had the time to create such package.

```{r functions}

mylog <- function(x, center = FALSE){
    if(min(x) <= 0) {tlog <- log1p}
    else {tlog <- log}

    logx <- tlog(x)

    if(isTRUE(center))
    {
        logx <- logx - tlog(mean(x))
    }

    if(is.numeric(center)){
        logx <- logx - tlog(center)
    }

    return(logx)

}

mkbin <- function(x,n = 0) ifelse(x > n, 1, 0)

capadjust <- function(x, y, K = 0) x/(K-y)

# Unconditional truncated means

tnb_mean <- function(mu, alpha) mu/(1-(1+alpha*mu)^(-1/alpha))
tp_mean <- function(mu) mu/(1-exp(-mu))


countsummary <- function(model){
    print(summary(model))
    print(confint(model))
    sgm <- sigma(model)

    if(length(sgm) == 0){
        sgm <- model$alpha
    }
    cat("\n\nAlpha: \n")
    print(1/sgm)
    cat("\nLog-likelihood: \n")
    print(logLik(model))
    cat("\n")
    print(car::Anova(model))
    print(lrtest(model))
    print(car::vif(model))
}

compare_nested <- function(...) {
    print(AICtab(...))
    print(lrtest(...))
}

## write a function to calculate the half-life
half_life <- function(model, hl = 0.50, ci = TRUE, ...){
    half_life <- log(hl)/coef(model)[2]
    results <- list(HL = half_life)
    if(ci){
        hl_ci <- log(hl)/confint(model, ...)[2,]
        results$CI <- hl_ci
    }
    return(results)
}

### Function to extract model coefficients to csv
## Should work for glmmTMB and glmmADMB models

coef_csv <- function(model, dir = "coef_results/"){
    if(class(model) == "glmmTMB"){
        coefs1 <- fixef(model)$cond
        ses1 <- sqrt(diag(vcov(model)$cond))
    } else{
        coefs1 <- coef(model)
        ses1 <- sqrt(diag(vcov(model)))
    }
    ncoefs1 <- length(coefs1)
    ses1 <- ses1[1:ncoefs1]

    confints1 <- confint(model)

    confints1 <- confints1[1:ncoefs1,1:2]

    mat <- cbind(coefs1,ses1,confints1)
    colnames(mat) <- c("Estimate", "SE", "CI_low", "CI_high")

    mname <- deparse(substitute(model))

    filename <- paste0(dir, mname, ".csv")

    write.csv(mat, file = filename)

    message("\nFile: '", filename, "' successfully writen!\n")

}

```

# Data input and processing

We first load and arrange the area and victim level data.

As the script is designed to be run remotely, when working locally during development, testing data needs to be downloaded from github. To download the testing data, the script uses an Rmarkdown parameter (`params$test`). The parameter is set to `FALSE` by default, so that it runs seamlessly using the `render` command when running in the remote research settings. For running correctly in a testing setting, the parameter must be given a `TRUE` value when running the knit command (`rmarkdown::render('ENVE_rv_ext_type.Rmd', params = list(test = TRUE))`). When using `knitr`, no parameter is passed, so the following gives an error. This is expected behaviour.

```{r testing}
#params <- list(test = TRUE)
if(params$test){
    download("https://raw.githubusercontent.com/prestevez/datahouse/master/enve2014cuest_ciega_2014.dbf",
                      destfile = "enve2014cuest_ciega_2014.dbf", mode = "wb")
    download("https://raw.githubusercontent.com/prestevez/datahouse/master/enve2014delitos_ciega_2014.dbf",
                 destfile = "enve2014delitos_ciega_2014.dbf", mode = "wb")
}

```

Next we explore what files are available in the working directory.

```{r files}

list.files()

```

Next we input the additional data needed for the analysis currently saved in Github.

```{r GH-data}

cat_entidades <- read.csv("https://raw.githubusercontent.com/prestevez/datahouse/master/cat_entidades.csv", head=TRUE)
state_level_data <- read.csv("https://raw.githubusercontent.com/prestevez/datahouse/master/state_level_data_2013.csv", header=TRUE)
state_level_data <- merge(state_level_data,
                          cat_entidades, by="CVE_ENT", all.x=TRUE)
scode <- read.csv("https://raw.githubusercontent.com/prestevez/datahouse/master/secode.csv", head=TRUE)
scode$Code <- scode$Code*10000


```

Now we are ready to input the victim-level data.

```{r victim-level-import}
enve_all <- read.dbf("enve2014cuest_ciega_2014.dbf")

```

To prepare the data for analysis we select only the variables that are used in the analysis.

```{r victim-level-processing}

enve_test <- data.frame(extortions=as.integer(as.character(enve_all$P26_10)))

enve_test$extortion_victim <- enve_all$P25_10
enve_test$extortions[enve_test$extortion_victim == 2] <- 0
summary(enve_test$extortions)
table(enve_test$extortions)

enve_test$extortions[is.na(enve_test$extortions)] <- 0

summary(enve_test$extortions)
table(enve_test$extortions)


enve_test$rep_extortion_victim <- mkbin(enve_test$extortions, 1)
#enve_test$rep_extortion_victim <- factor(enve_test$extortions)
#levels(enve_test$rep_extortion_victim) <- c(0, 0,
#                    rep(1, length(levels(enve_test$rep_extortion_victim)) - 2))

table(enve_test$rep_extortion_victim)

enve_test$rep_extortions <- enve_test$extortions
enve_test$rep_extortions[enve_test$rep_extortions > 0] <- enve_test$rep_extortions[enve_test$rep_extortions > 0] - 1

summary(enve_test$rep_extortions)
table(enve_test$rep_extortions)


enve_test$CVE_UNICA <- as.integer(as.character(enve_all$ID_CONSECU))

enve_test$bribes <- as.integer(as.character(enve_all$P33))
summary(enve_test$bribes)

# 4 bribe cats
enve_test$bribe1 <- enve_all$P29_1
enve_test$bribe2 <- enve_all$P30_1
enve_test$bribe3 <- enve_all$P31_1
enve_test$bribe4 <- enve_all$P32_1

enve_test$bribes[with(enve_test,
                        bribe1 == 2 &
                        bribe2 == 2 &
                        bribe3 == 2 &
                        bribe4 == 2)] <- 0

summary(enve_test$bribes)

enve_test$bribes[is.na(enve_test$bribes)] <- 0

enve_test$bribe_victim <- mkbin(enve_test$bribes, 0)

table(enve_test$bribe_victim)

enve_test$rep_bribe <- mkbin(enve_test$bribes, 1)

table(enve_test$rep_bribe)

enve_test$bribe_cats <- factor(enve_test$bribes)
levels(enve_test$bribe_cats) <- c(0, 1, 2, rep("3+",
                                            length(levels(enve_test$bribe_cats)) - 3))
summary(enve_test$bribe_cats)

enve_test$CVE_ENT <- as.integer(as.character(enve_all$CVE_ENT))

enve_test$size <- enve_all$ID_ESTRATO
levels(enve_test$size) <- c("Large", "Medium", "Small", "Micro")

enve_test$sector <- enve_all$SECTOR_FIN

# subsector
enve_test$tempsub <- as.integer(as.character(enve_all$P1_1B))
enve_test$subsector <- cut(enve_test$tempsub, scode$Code, right=FALSE)
levels(enve_test$subsector) <- scode$Sector
enve_test$subsector <- droplevels(enve_test$subsector)
enve_test$subsector <- relevel(enve_test$subsector, ref="Retail")
levels(enve_test$subsector)

enve_test$subsector_safe <- enve_test$subsector

enve_test$subsector <- as.character(enve_test$subsector)

# Must remember to exclude utilities from analysis

enve_test$subsector[enve_test$subsector %in%
                      c("Mining",
                        "Construction")] <- "Other industry"

# Must remember to exclude Corporate from analysis

enve_test$subsector[enve_test$subsector %in%
                      c("Media",
                        "Maintenance",
                        "Other",
                        "Finance",
                        "Health",
                        "Leisure",
                        "Education",
                        "Prof. services",
                        "Real estate")] <- "Other serv."


enve_test$subsector <- as.factor(enve_test$subsector)
enve_test$subsector <- relevel(enve_test$subsector, ref="Retail")
levels(enve_test$subsector)
summary(enve_test$subsector)

enve_test$years <- 2013 - as.numeric(as.character(enve_all$P3))
summary(enve_test$years)

intyears <- classInt::classIntervals(enve_test$years, 5, style="quantile")
enve_test$yearsquant <- cut(enve_test$years, intyears$brks, right=TRUE,
                            include.lowest = TRUE)

enve_test <- merge(enve_test, state_level_data, by="CVE_ENT", all.x=TRUE)

length(enve_test$extortions[is.na(enve_test$extortions)])
length(enve_test$bribes[is.na(enve_test$bribes)])

## enve_test$extortions[is.na(enve_test$extortions)] <- 0
## enve_test$bribes[is.na(enve_test$bribes)] <- 0

summary(enve_test)

# Exclude Corporate and Utilitites

nrow(enve_test) # should be 28179


enve_test %>%
    filter(subsector != "Utilities") %>%
    filter(subsector != "Corporate") -> enve_test_2

enve_test_2$subsector <- droplevels(enve_test_2$subsector)

levels(enve_test_2$subsector)

enve_test_2$subsector_safe <- droplevels(enve_test_2$subsector_safe)
levels(enve_test_2$subsector_safe)

nrow(enve_test_2) # should be 28161

enve_test <- enve_test_2
nrow(enve_test)

summary(enve_test)
```

Next we import and prepare the incident-level data.

```{r incident-level}

enve_incidents_all <- read.dbf("enve2014delitos_ciega_2014.dbf")

# Selecting only those relevant for extortion (code 10)

enve_incidents_all$delito <- as.integer(as.character(enve_incidents_all$ID_DELITO))

enve_incidents <- enve_incidents_all[enve_incidents_all$delito == 10,]

# Selecting those relevant for our study

incident_df <- data.frame(CVE_UNICA=as.integer(as.character(enve_incidents$ID_CONSECU)))

incident_df$month <- as.numeric(as.character(enve_incidents$M1_1))

incident_df$delito <- enve_incidents$delito

incident_df$n_offenders <- enve_incidents$M1_8
summary(incident_df$n_offenders)

levels(incident_df$n_offenders) <- c(1:6, "DK/DA")
summary(incident_df$n_offenders)

incident_df$n_offenders_NA <-  incident_df$n_offenders
incident_df$n_offenders_NA[is.na(incident_df$n_offenders)] <- "DK/DA"
summary(incident_df$n_offenders_NA)

incident_df$n_offenders_old <- incident_df$n_offenders_NA
levels(incident_df$n_offenders_NA) <- c(1:3, "4+", "4+", "4+", "DK/DA")
summary(incident_df$n_offenders_NA)

incident_df$uk_n_offenders <- incident_df$n_offenders_NA

levels(incident_df$uk_n_offenders)[1:4] <- "known"

incident_df$n_offenders_num <- enve_incidents$M1_8
summary(incident_df$n_offenders_num)
levels(incident_df$n_offenders_num) <- c(1:6, 0)
summary(incident_df$n_offenders_num)
incident_df$n_offenders_num[is.na(incident_df$n_offenders_num)] <- 0
incident_df$n_offenders_num <- as.numeric(as.character(incident_df$n_offenders_num))
table(incident_df$n_offenders_num)

incident_df$n_offenders_num <- incident_df$n_offenders_num - 1


## Data imputation for missing variables?

incident_df$rel_offenders <- enve_incidents$M1_11
levels(incident_df$rel_offenders) <- c("Known", "Known",
                                       "Known", "Known",
                                       "Total stranger", "DK/DA")
incident_df$rel_offenders <- relevel(incident_df$rel_offenders, ref="Total stranger")
summary(incident_df$rel_offenders)

incident_df$rel_offenders_NA <- incident_df$rel_offenders
incident_df$rel_offenders_NA[is.na(incident_df$rel_offenders_NA)] <- "DK/DA"
summary(incident_df$rel_offenders_NA)

incident_df$had_weapon <- enve_incidents$M1_13
levels(incident_df$had_weapon) <- c("Yes", "No", "DK/DA")
incident_df$had_weapon <- relevel(incident_df$had_weapon, ref="No")
summary(incident_df$had_weapon)

incident_df$had_weapon_NA <- incident_df$had_weapon
incident_df$had_weapon_NA[is.na(incident_df$had_weapon_NA)] <- "DK/DA"
summary(incident_df$had_weapon_NA)

incident_df$extortion_type <- as.character(enve_incidents$M5_1)
incident_df$extortion_type <- as.factor(incident_df$extortion_type)
levels(incident_df$extortion_type) <- c("Remote", "Remote", "Street",
                                        "Premises", "Cobro de piso", "Other")
levels(incident_df$extortion_type)
summary(incident_df$extortion_type)

incident_df$extortion_type_bin <- as.character(enve_incidents$M5_1)
incident_df$extortion_type_bin <- as.factor(incident_df$extortion_type_bin)
levels(incident_df$extortion_type_bin) <- c("Remote", "Remote", "In person",
                                        "In person", "In person", "Other")
levels(incident_df$extortion_type_bin)
summary(incident_df$extortion_type_bin)

# Extortion bin w/o Cobro de piso
incident_df$extortion_type_wocp <- as.character(enve_incidents$M5_1)
incident_df$extortion_type_wocp <- as.factor(incident_df$extortion_type_wocp)
levels(incident_df$extortion_type_wocp) <- c("Remote", "Remote", "In person",
                                        "In person", "Other", "Other")
levels(incident_df$extortion_type_wocp)
summary(incident_df$extortion_type_wocp)


incident_df$complied <- enve_incidents$M5_3
levels(incident_df$complied) <-  c("Yes", "No", "DK/DA")
incident_df$complied <- relevel(incident_df$complied, ref="No")
summary(incident_df$complied)


incident_df$complied_bin <- enve_incidents$M5_3
levels(incident_df$complied_bin) <-  c("Yes", "No", NA)
incident_df$complied_bin <- relevel(incident_df$complied_bin, ref="No")
summary(incident_df$complied_bin)


incident_df$complied_bin_NA <- incident_df$complied_bin
incident_df$complied_bin_NA[is.na(incident_df$complied_bin_NA)] <- "No"
summary(incident_df$complied_bin_NA)

incident_df <- subset(incident_df, extortion_type != "Other")
incident_df$extortion_type <- droplevels(incident_df$extortion_type)

# Remember to subset out "other" obs from extortion_type_wocp
incident_df$extortion_type_bin <- droplevels(incident_df$extortion_type_bin)

summary(incident_df)
```

Next we merge both incident-level and victim-level tables.

```{r incident-victim-merge}
enve_incvic <- merge(incident_df, enve_test, by="CVE_UNICA")

nrow(enve_incvic)
nrow(incident_df)
```


# Revisions to compliance study

No revisions necessary.

Further data processing required for compliance study. Subsetting data excluding NA values.

```{r subset-no-NA}

## datasets with no NA values first.

nacols <- colnames(enve_incvic)[colSums(is.na(enve_incvic)) > 0]

nonacols <- names(enve_incvic)[!(names(enve_incvic) %in% nacols)]
nonacols
enve_incvic %>%
    select(nonacols) -> enve_nona

summary(enve_nona)
nrow(enve_nona)
nrow(enve_nona[complete.cases(enve_nona),])
nrow(enve_nona[complete.cases(enve_incvic),])

## Data structure

"number of incidents"
nrow(enve_nona)

"incidents per business"
table(table(enve_nona$CVE_UNICA))
enve_nona %>%
    count(CVE_UNICA) %>%
    summarise(min(n),
              max(n),
              mean(n),
              n())

"number of incidents per state"
enve_nona %>%
    count(CVE_ENT) %>%
    summarise(min(n),
              mean(n),
              max(n),
              n())

"number of businesses per state"
enve_nona %>%
    count(CVE_ENT, CVE_UNICA) %>%
    count(CVE_ENT) %>%
    summarise(min(nn),
              mean(nn),
              max(nn))

```

Calculate the national means of the state-level variables used in the models.

```{r state-level-means}

mean_bribes <- mean(state_level_data$bribes_abvic)
mean_bribes

mean_armas <- mean(state_level_data$armas)
mean_armas

mean_drogas <- mean(state_level_data$drogas)
mean_drogas

mean_poblacion <- mean(state_level_data$poblacion)
mean_poblacion

mean_N <- mean(state_level_data$N)
mean_N

mean_General <- mean(state_level_data$General)
mean_General

mean_Derecho <- mean(state_level_data$Derecho)
mean_Derecho


```

# Event dependence study

Several things to improve over previous iteration.

Time course analysis: Only by type, don't do for all extortions.

Do EDA of victimisation frequency per month and semester

Redo timecourse plots, make sure they are correctly saved in the figure folder. Also add labels for every month.

When excluding semester wise observations that have reached the cap, mention how many had to be excluded.

Fix case compliance variable, change OR for AND

After lag adjust, fit to

Do plots of lag adjusted to get a sense of how many there are.

Also do a scatter plot vs unadjusted? (can exclude zeroes)

Fix compliance formulas

As previous chapter showed incidence not best approach, maybe focus only on prevalence vs concentration here. Focus on event dependence, add risk heterogeneity as controls. Use previous iteration to identify best model, but check *final* specs against overdispersion and multilevel.

Fix business size category.

## Time course


```{r time-course, fig.width = 7, fig.height = 4}

## Tables and tests by type

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "Remote") %$%
    table(month, useNA = "ifany")

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "Remote") %$%
    table(month, useNA = "ifany")%>%
    chisq.test

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "In person") %$%
    table(month, useNA = "ifany")

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "In person") %$%
    table(month, useNA = "ifany")%>%
    chisq.test

# plots

(enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp != "Other") %>%
    ggplot(aes(month, fill = extortion_type_wocp)) +
    geom_bar() +
    theme_bw() +
    scale_x_continuous("Month", breaks = 1:12) +
    ylab("Extortion incidents") +
    ggtitle("Extortion incidents (monthly)") +
    facet_wrap(~ extortion_type_wocp, scales = "free_y") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none") -> monthly_counts_plot)

ggsave(monthly_counts_plot, filename = "figure/monthly_counts_extortion.pdf", width = 7, height = 4)


# events per semester

### per type

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "In person") %>%
    mutate(sem = case_when(
        month < 7   ~ 0,
        month >= 7  ~ 1
    )) %$%
    table(sem, useNA = "ifany")

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "In person") %>%
    mutate(sem = case_when(
        month < 7   ~ 0,
        month >= 7  ~ 1
    ))%$%
    table(sem, useNA = "ifany") %>%
    chisq.test

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "Remote") %>%
    mutate(sem = case_when(
        month < 7   ~ 0,
        month >= 7  ~ 1
    )) %$%
    table(sem, useNA = "ifany")

enve_nona %>%
    filter(month < 13) %>%
    filter(extortion_type_wocp == "Remote") %>%
    mutate(sem = case_when(
        month < 7   ~ 0,
        month >= 7  ~ 1
    ))%$%
    table(sem, useNA = "ifany") %>%
    chisq.test


#### TC
enve_nona %>%
    filter(month < 13) %>%
    #select(CVE_UNICA, month) %>%
    arrange(CVE_UNICA, month) -> id_mth


```


### Time course for remote extortions

To analyse the time course per event type, the TC column must be recalculated after subsetting events by type.


```{r time-course-remote}

# filter data set using the following
id_mth %>%
    filter(extortion_type_wocp == "Remote") %>%
    group_by(CVE_UNICA) %>%
    mutate(lmonth = lag(month)) %>%
    drop_na %>%
    mutate(tc = month - lmonth) -> tc_remote

### Calculate time courses using:

### Full period
tc_remote %$%
    table(tc) %>%
    data.frame %>%
    transmute(time = as.integer(as.character(tc)),
                count = Freq,
                prop = count/sum(count)) -> tc_remote_tb

tc_remote_tb


tc_remote_model <- glm(prop ~ time, data = tc_remote_tb,
                    family = gaussian(link = "log"))

summary(tc_remote_model)

lrtest(tc_remote_model)


half_life(tc_remote_model)


tc_remote_tb %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"), colour = "black",
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat remote extortion victimisation") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom")  +
            scale_x_continuous(breaks = 0:11) +
            scale_y_continuous(labels = scales::percent)




## 6m time window

tc_remote %>%
    filter(month > 5) %>%
    filter(tc < 7) %$%
    table(tc) %>%
    data.frame %>%
    transmute(time = as.integer(as.character(tc)),
                count = Freq,
                prop = count/sum(count)) -> tc_remote_6m_tb

tc_remote_6m_tb

tc_remote_model_6m <- glm(prop ~ time, data = tc_remote_6m_tb,
                    family = gaussian(link = "log"))

summary(tc_remote_model_6m)

lrtest(tc_remote_model_6m)


half_life(tc_remote_model_6m)


tc_remote_6m_tb %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"), colour = "black",
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat remote extortion victimisation \n(6 month time window)") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
            scale_x_continuous(breaks = 0:11) +
            scale_y_continuous(labels = scales::percent)


```


### Time course for in-person extortions

Now we estiamte the time course for in-persone extortions (excluding of course cobro de piso, as these do not have repeats).


```{r time-course-in-person}

# filter data set using the following

id_mth %>%
    filter(extortion_type_wocp == "In person") %>%
    group_by(CVE_UNICA) %>%
    mutate(lmonth = lag(month)) %>%
    drop_na %>%
    mutate(tc = month - lmonth) -> tc_inp

### Calculate time courses using:

### Full period
tc_inp %$%
    table(tc) %>%
    data.frame %>%
    transmute(time = as.integer(as.character(tc)),
                count = Freq,
                prop = count/sum(count)) -> tc_inp_tb

tc_inp_tb


tc_inp_model <- glm(prop ~ time, data = tc_inp_tb,
                    family = gaussian(link = "log"))

summary(tc_inp_model)

lrtest(tc_inp_model)


half_life(tc_inp_model)


tc_inp_tb %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"), colour = "black",
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat in-person extortion victimisation") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
            scale_x_continuous(breaks = 0:11) +
            scale_y_continuous(labels = scales::percent)




## 6m time window

tc_inp %>%
    filter(month > 5) %>%
    filter(tc < 7) %$%
    table(tc) %>%
    data.frame %>%
    transmute(time = as.integer(as.character(tc)),
                count = Freq,
                prop = count/sum(count)) -> tc_inp_6m_tb

tc_inp_6m_tb

tc_inp_model_6m <- glm(prop ~ time, data = tc_inp_6m_tb,
                    family = gaussian(link = "log"))

summary(tc_inp_model_6m)

lrtest(tc_inp_model_6m)


half_life(tc_inp_model_6m)


tc_inp_6m_tb %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"), colour = "black",
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat remote extortion victimisation \n(6 month time window)") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
            scale_x_continuous(breaks = 0:11) +
            scale_y_continuous(labels = scales::percent)


```


Generate a plot combining the time course of both types

```{r combined-time-course}


tc_remote_tb %>%
    mutate(Type = "Remote extortion") %>%
    bind_rows(mutate(tc_inp_tb, Type = "In-person extortion")) -> tc_both


(tc_both %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"),
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat extortion victimisation") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
    facet_wrap(~ Type)  +
    scale_x_continuous(breaks = 0:11) +
    scale_y_continuous(labels = scales::percent)  -> tc_both_p1)

ggsave(tc_both_p1, file = "figure/tc_both_p1.pdf",
        width = 8, height = 4)

## using 6m time window

tc_remote_6m_tb %>%
    mutate(Type = "Remote extortion") %>%
    bind_rows(mutate(tc_inp_6m_tb, Type = "In-person extortion")) -> tc_both_6m


(tc_both_6m %>%
    ggplot(aes(time, prop)) +
    geom_smooth(aes(linetype = "Exponential"),
                method = "glm", se = FALSE,
                method.args = list(family = gaussian(link = "log"))) +
    geom_line(aes(linetype = "Observed"))  +
    theme_bw() +
    ggtitle("Time course of repeat extortion victimisation \n(6 month time window)") +
    xlab("Months between repeat events") +
    ylab("Proportion") +
    theme(legend.title = element_blank(),
            legend.position = "bottom") +
    facet_wrap(~ Type)  +
    scale_x_continuous(breaks = 0:11) +
    scale_y_continuous(labels = scales::percent)  -> tc_both_6m_p1)

ggsave(tc_both_6m_p1, file = "figure/tc_both_6m_p1.pdf",
        width = 7, height = 4)

```

## Modelling event dependence

One option is to divide the extortion observation into at least two periods, e.g. first and second semester, and model the prevalence, incidence and concentration of extortion in the second semester, with the count for the previous semester as a covariate. This is simple, but has several limitations. If the time-course of repeat victimisation suggests a rapid decay in victimisation risk, then there will be very few businesses that faced victimisation the previous semester---event dependence won't be captured and will be a part of unobserved heterogeneity. Second, the lagged covariate will likely be correlated with the additional time-invariant covariates, which could bias the results. (Capping adjustments or categorical variables may mitigate this)

Another option is to build a longer panel and control for unit fixed effects, that way the time-invariant covariates would not be needed: they could be dropped. An additional advantage would be that this approach would be able to capture event dependence with a steeper decay function---capturing the effect of event dependence between months, instead of semesters. The `pglm` package could be used for panel logit and count models. A problem is that observations would very likely be serially correlated, and I am unsure if there are suitable methods to detect and correct serial correlation for negbin models. This approach could also magnify any measurement errors in the way event and month data is captured, which has not been fully examined. The longer the panel, the more error would be introduced as we would be synthetically creating a panel based on cross-sectional measurements.

For this exercise, I believe a two semester panel is a good compromise between the amount of error that is introduced and the explanatory power of the model.

Another complication is that as the data is capped, the number of observations in the lagged count is a function of the number of counts in the dependent variable (or in other extortion events). Thus the Event Dependence indicator should account for this and represent instead the number of incidents suffered over the maximum number of incidents that a unit could suffer--however, this might require dropping observations that reach the cap in semester 2 (that are incapable of suffering an event in semester 1 due to the amount of events suffered in semester 2).

Lastly, it would be particularly interesting to explore not only if the amount of victimisation suffered in the previous semester is a predictor, but also if complying with an event has implications for event dependence. A good approach to operationalise this would be using categorical variables (not a victim, victim did not comply, victim-complied).

### Data wrangling

Before the analysis, a data frame splitting the extortion counts by semester must be constructed.

Then select only observations from semester 2.

Models for lag dependence should exclude those observations where it is impossible to suffer extortions in one period because the cap is reached in one semester. These situations would occour if:

- extincs (in sem 2) is 7
- lag_extincs (in sem1) is 7

Previous iterations of the analysis suggest that there are some cases where this happens.

In extincs there are 6 cases that are equal to 7, similarly there are 6 cases where lag_extincs is 7.


```{r semester-counts}

# Create a semester column

enve_nona %>%
    mutate(semester = ifelse(month < 7, 0,
                    ifelse(month > 12, 99, 1))) -> enve_mths_plus


enve_mths_plus %$%
    table(semester, useNA = "ifany")

# Identify CVE_UNICAS with no month

enve_mths_plus %>%
    filter(semester == 99) %$%
    unique(CVE_UNICA) -> non_month_cu

## Add semester as grouping factor

enve_mths_plus %>%
    group_by(CVE_UNICA, semester) %>%
    filter(semester != 99) %>%
    summarise(extincs = n(),
              complied = sum(complied_bin_NA == "Yes"),
              remote = sum(extortion_type == "Remote"),
              piso = sum(extortion_type == "Cobro de piso"),
              inperson = sum(extortion_type_wocp == "In person"),
              comp_remote  = sum(extortion_type_bin == "Remote" & complied_bin_NA == "Yes"),
              comp_inperson  = sum(extortion_type_wocp == "In person" & complied_bin_NA == "Yes")) %>%
              complete(CVE_UNICA,
                  semester = c(0,1)) %>%
              replace(is.na(.), 0) -> enve_bus_lev_semester

enve_bus_lev_semester %$%
    table(semester, useNA = "ifany")

enve_bus_lev_semester %$%
    CVE_UNICA %in% non_month_cu %>% table


#enve_bus_lev %>%
#    group_by(CVE_UNICA) %>%
#    summarise(n = max(extincs)) %$% range(n)

enve_bus_lev_semester %>%
    group_by(CVE_UNICA, semester) %>%
    summarise(n = max(extincs)) %$% range(n)

### Merge with the enve_test data, keeping non victims as 0

enve_test %$%
    data.frame(CVE_UNICA = rep(CVE_UNICA, each = 2),
                semester = 0:1) -> enve_ids_semester

enve_test %>%
    left_join(enve_ids_semester, by = "CVE_UNICA") -> enve_plus_ids_sem

enve_plus_ids_sem %>%
    left_join(enve_bus_lev_semester) -> enve_plus_sem

enve_plus_sem %$%
    table(semester, useNA = "ifany")


enve_plus_sem %>%
    group_by(semester) %>%
    summarise(max(extincs))

enve_plus_sem %>%
    replace(is.na(.), 0) -> enve_sem_nona

enve_sem_nona %>%
    group_by(semester) %>%
    summarise(max(extincs))

nrow(enve_plus_sem)

nrow(enve_sem_nona)


## Add lagged columns for all capped counts

enve_sem_nona %>%
    group_by(CVE_UNICA) %>%
    mutate(lag_extincs = lag(extincs, order_by = semester),
            lag_remote = lag(remote, order_by = semester),
            lag_inperson = lag(inperson, order_by = semester),
            lag_piso = lag(piso, order_by = semester),
            lag_complied = lag(complied, order_by = semester),
            lag_comp_remote = lag(comp_remote, order_by = semester),
            lag_comp_inperson = lag(comp_inperson,
                order_by = semester)) -> enve_sem_lag


length(non_month_cu)

enve_sem_lag %>%
    filter(!CVE_UNICA %in% non_month_cu) -> enve_lag_nm

nrow(enve_lag_nm)

enve_sem_lag %$%
    table(extincs)

enve_lag_nm %$%
    table(extincs)

enve_sem_lag %$%
    table(remote)

enve_lag_nm %$%
    table(remote)

enve_sem_lag %$%
    table(inperson)

enve_lag_nm %$%
    table(inperson)

### select semester 2
# Exclude obs where Cap is reached one semester

enve_lag_nm %>%
    filter(semester > 0) %>%
    filter(extincs < 7) %>%
    filter(lag_extincs < 7) -> enve_lag_nm_sem1


enve_lag_nm_sem1 %$%
    table(extincs)

enve_lag_nm_sem1 %$%
    table(lag_extincs)

enve_lag_nm_sem1 %$%
    table(remote)

enve_lag_nm_sem1 %$%
    table(lag_remote)

enve_lag_nm_sem1 %$%
    table(inperson)

enve_lag_nm_sem1 %$%
    table(lag_inperson)

## Add subsector new category

enve_lag_nm_sem1$subsector_new <- enve_lag_nm_sem1$subsector

levels(enve_lag_nm_sem1$subsector_new) <- c('Retail',
                                        'HotelsRestBar',
                                        'Industry' ,
                                        'Industry',
                                        'Other serv.',
                                        'Other serv.',
                                        'Wholesale')


## Change Business size categories

enve_lag_nm_sem1$size_old <- enve_lag_nm_sem1$size

sizelevels <- levels(enve_lag_nm_sem1$size)

levels(enve_lag_nm_sem1$size) <- c('Large', 'MedSmall', 'MedSmall', 'Micro')


```

### EDA

Do extensive EDA to understand if any variable has complete or quasi-complete separation (business and state level)

Examine EDA (and models) from previous iterations see if some categories indicate complete or quasi-complete separation.


```{r semester-eda}

#### Remote extortions

ed_remote_eda_f <- mkbin(remote) ~ factor(mkbin(lag_remote)) +
                                   factor(mkbin(lag_remote, 1)) +
                                   factor(mkbin(lag_comp_remote)) +
                                   bribes +
                                   yearsquant +
                                   size +
                                   subsector_new

ed_remote_eda <- tableby(ed_remote_eda_f,
                        data  = enve_lag_nm_sem1)

summary(ed_remote_eda,
            pfootnote = TRUE)

## repeat extortions


ed_remote_eda_f_repeats <- update(ed_remote_eda_f, mkbin(remote, 1) ~ .)

ed_remote_eda_reps <- tableby(ed_remote_eda_f_repeats,
                        data  = enve_lag_nm_sem1)

summary(ed_remote_eda_reps,
            pfootnote = TRUE)

#### In person extortions

ed_inp_eda_f <- mkbin(inperson) ~ factor(mkbin(lag_inperson)) +
                                   factor(mkbin(lag_inperson, 1)) +
                                   factor(mkbin(lag_comp_inperson)) +
                                   bribes +
                                   yearsquant +
                                   size +
                                   subsector_new

ed_inp_eda <- tableby(ed_inp_eda_f,
                        data  = enve_lag_nm_sem1)

summary(ed_inp_eda,
            pfootnote = TRUE)

## repeat extortions

ed_inp_eda_f_repeats <- update(ed_inp_eda_f, mkbin(inperson, 1) ~ .)

ed_inp_eda_reps <- tableby(ed_inp_eda_f_repeats,
                        data  = enve_lag_nm_sem1)

summary(ed_inp_eda_reps,
            pfootnote = TRUE)

```

Plot and table distribution


```{r ed-plots-tables}

# Semester 1

enve_lag_nm_sem1 %>%
    ungroup %>%
    select(remote, inperson) %>%
    melt %>%
    mutate(variable = fct_recode(variable,
            Remote = "remote",
            "In person" = "inperson")) %>%
    group_by(variable) %>%
    ggplot(aes(value, fill = variable)) +
    geom_bar() +
    scale_y_sqrt("Businesses") +
    scale_x_continuous(breaks = 0:7) +
    theme_bw() +
    xlab("Incidents per business") +
    facet_wrap(~ variable, scales = "free_y") +
    ggtitle("Distributon of extortion by type (capped at 7)",
            subtitle = "Second semester of 2014") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/capped_dist_sqrt_sem1.pdf", width = 7, height = 4)


enve_lag_nm_sem1 %>%
    ungroup %>%
    select(remote, inperson) %>%
    melt %>%
    mutate(variable = fct_recode(variable,
            Remote = "remote",
            "In person" = "inperson")) %>%
    group_by(variable) %>%
    ggplot(aes(value, fill =  variable)) +
    geom_bar() +
    scale_y_continuous("Businesses", trans = "log1p") +
    scale_x_continuous(breaks = 0:7) +
    theme_bw() +
    xlab("Incidents per business") +
    facet_wrap(~ variable, scales = "free_y") +
    ggtitle("Distributon of extortion by type (capped at 7)",
            subtitle = "Second semester of 2014") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/capped_dist_log1p_sem1.pdf", width = 7, height = 4)


# Semester 0

enve_lag_nm_sem1 %>%
    ungroup %>%
    select(lag_remote, lag_inperson) %>%
    melt %>%
    mutate(variable = fct_recode(variable,
            Remote = "lag_remote",
            "In person" = "lag_inperson")) %>%
    group_by(variable) %>%
    ggplot(aes(value, fill =  variable)) +
    geom_bar() +
    scale_y_sqrt("Businesses") +
    scale_x_continuous(breaks = 0:7) +
    theme_bw() +
    xlab("Incidents per business") +
    facet_wrap(~ variable, scales = "free_y") +
    ggtitle("Distributon of extortion by type (capped at 7)",
            subtitle = "First semester of 2014") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/capped_dist_sqrt_sem0.pdf", width = 7, height = 4)


enve_lag_nm_sem1 %>%
    ungroup %>%
    select(lag_remote, lag_inperson) %>%
    melt %>%
    mutate(variable = fct_recode(variable,
            Remote = "lag_remote",
            "In person" = "lag_inperson")) %>%
    group_by(variable) %>%
    ggplot(aes(value, fill =  variable)) +
    geom_bar() +
    scale_y_continuous("Businesses", trans = "log1p") +
    scale_x_continuous(breaks = 0:7) +
    theme_bw() +
    xlab("Incidents per business") +
    facet_wrap(~ variable, scales = "free_y") +
    ggtitle("Distributon of extortion by type (capped at 7)",
            subtitle = "First semester of 2014") +
    scale_fill_manual(values = c("#E69F00", "#0072B2")) +
    theme(legend.position = "none")

ggsave(filename = "figure/capped_dist_log1p_sem0.pdf", width = 7, height = 4)

## tables

enve_lag_nm_sem1 %$%
    victim_table(remote, "pandoc")

enve_lag_nm_sem1 %$%
    victim_table(lag_remote, "pandoc")

enve_lag_nm_sem1 %$%
    victim_table(inperson, "pandoc")

enve_lag_nm_sem1 %$%
    victim_table(lag_inperson, "pandoc")


```


### Modelling

Modelling:

- Prevalence
- Concentration

Follow this procedure:

1. Fit model with lag (test overdispersion and multilevel)
2. Add risk controls
2. Test overdispersion and multilevel
3. Repeat for other measures of lag (adj and compliance)


Generate a compliance categorical (Not victimised, victimised but not complied, complied)

```{r compliance-categorical}

case_compliance <- function(x, y){
    a <- case_when(
        x == 0          ~ "Not victim",
        x > 0 & y == 0  ~ "Victim, not comp.",
        y > 0           ~ "Complied"
    )
    factor(a, levels = c("Not victim", "Victim, not comp.", "Complied"))
}

enve_lag_nm_sem1 %>%
    mutate(
        lag_comp_cat = case_compliance(lag_extincs, lag_complied),
        lag_rmt_comp_cat = case_compliance(lag_remote, lag_comp_remote),
        lag_inp_comp_cat = case_compliance(lag_inperson, lag_comp_inperson)
    ) -> enve_lag_nm_sem1

enve_lag_nm_sem1 %$%
    table(lag_comp_cat)

enve_lag_nm_sem1 %$%
    table(lag_rmt_comp_cat)

enve_lag_nm_sem1 %$%
    table(lag_inp_comp_cat)

```

Also generate a numerical variable adjusting the lag value.

```{r lag-cap-adjusted}

enve_lag_nm_sem1 %>%
    mutate(
        lag_extincs_adj = capadjust(lag_extincs, extincs, 7),
        lag_rmt_adj = capadjust(lag_remote, extincs + lag_extincs - lag_remote, 7),
        lag_inp_adj = capadjust(lag_inperson, extincs + lag_extincs - lag_inperson, 7)
    ) -> enve_lag_nm_sem1


enve_lag_nm_sem1 %$%
    table(lag_extincs_adj, useNA = "ifany")

enve_lag_nm_sem1 %$%
    table(lag_rmt_adj, useNA = "ifany")

enve_lag_nm_sem1 %$%
    table(lag_inp_adj, useNA = "ifany")


enve_lag_nm_sem1 %$%
    anyNA(lag_rmt_adj)

enve_lag_nm_sem1 %$%
    anyNA(lag_inp_adj)

enve_lag_nm_sem1 %>%
    drop_na -> enve_lag_nm_sem1_nona

nrow(enve_lag_nm_sem1)
nrow(enve_lag_nm_sem1_nona)


```

EDA of the new variables

```{r eda-comp-cats}

# remote extortions

comp_cat_rmt_eda <- tableby(mkbin(remote) ~ lag_rmt_comp_cat,
                        data  = enve_lag_nm_sem1_nona)

summary(comp_cat_rmt_eda,
            pfootnote = TRUE)

# repeat remote extortions

comp_cat_rmt_eda_r <- tableby(mkbin(remote, 1) ~ lag_rmt_comp_cat,
                        data  = enve_lag_nm_sem1_nona)

summary(comp_cat_rmt_eda_r,
            pfootnote = TRUE)


# inperson extortions

comp_cat_inp_eda <- tableby(mkbin(inperson) ~ lag_inp_comp_cat,
                        data  = enve_lag_nm_sem1_nona)

summary(comp_cat_inp_eda,
            pfootnote = TRUE)

# repeat inperson extortions

comp_cat_inp_eda_r <- tableby(mkbin(inperson, 1) ~ lag_inp_comp_cat,
                        data  = enve_lag_nm_sem1_nona)

summary(comp_cat_inp_eda_r,
            pfootnote = TRUE)




```

```{r eda-adj-lag}

# remote extortions

adj_lag_rmt_eda <- tableby(mkbin(remote) ~ lag_rmt_adj,
                        data  = enve_lag_nm_sem1_nona)

summary(adj_lag_rmt_eda,
            pfootnote = TRUE)

# repeat remote extortions

adj_lag_rmt_eda_r <- tableby(mkbin(remote, 1) ~ lag_rmt_adj,
                        data  = enve_lag_nm_sem1_nona)

summary(adj_lag_rmt_eda_r,
            pfootnote = TRUE)


# inperson extortions

adj_lag_inp_eda <- tableby(mkbin(inperson) ~ lag_inp_adj,
                        data  = enve_lag_nm_sem1_nona)

summary(adj_lag_inp_eda,
            pfootnote = TRUE)

# repeat inperson extortions

adj_lag_inp_eda_r <- tableby(mkbin(inperson, 1) ~ lag_inp_adj,
                        data  = enve_lag_nm_sem1_nona)

summary(adj_lag_inp_eda_r,
            pfootnote = TRUE)



```


#### Remote

Model event dependence on remote extortions.

Do only prevalence (logit) and concentration (truncated count) models.


```{r remote-event-dependence-prevalence}

## Use enve_lag_nm_sem1_nona

# Bivariate model of event dependence

add_nom <- . ~ . + (1|NOM_ENT)

ed_rmt_logit <- glmmTMB(mkbin(remote) ~ lag_remote,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_rmt_logit)

# Test multilevel

ed_rmt_mlogit <- update(ed_rmt_logit, add_nom)

countsummary(ed_rmt_mlogit)

compare_nested(ed_rmt_logit, ed_rmt_mlogit)


### Risk heterogeneity

add_risk <-  . ~ . + mylog(bribes) +
                    yearsquant +
                    subsector_new +
                    size +
                    mylog(bribes_abvic, mean_bribes) +
                    mylog(armas, mean_armas) +
                    mylog(drogas, mean_drogas) +
                    mylog(N, mean_N) +
                    mylog(poblacion, mean_poblacion) +
                    scale(General, mean_General, FALSE) +
                    scale(Derecho, mean_Derecho, FALSE)


ed_rmt_mlogit_risk_lag <- update(ed_rmt_mlogit, add_risk)

countsummary(ed_rmt_mlogit_risk_lag)

## Compare to single level

ed_rmt_logit_risk_lag <- update(ed_rmt_mlogit_risk_lag, . ~ . - (1|NOM_ENT))

countsummary(ed_rmt_logit_risk_lag)

compare_nested(ed_rmt_logit_risk_lag, ed_rmt_mlogit_risk_lag)

#### Remove lag from risk_lag

ed_rmt_mlogit_risk <- update(ed_rmt_mlogit_risk_lag,
            . ~ . - lag_remote)

countsummary(ed_rmt_mlogit_risk)


# lag to risk

compare_nested(ed_rmt_mlogit_risk, ed_rmt_mlogit_risk_lag)

#### Lag to risk

compare_nested(ed_rmt_mlogit, ed_rmt_mlogit_risk_lag)

coef_csv(ed_rmt_mlogit)
coef_csv(ed_rmt_mlogit_risk)
coef_csv(ed_rmt_mlogit_risk_lag)

## Then lag_rmt_adj

# Bivariate model of event dependence

ed_rmt_logit_adj <- glmmTMB(mkbin(remote) ~ lag_rmt_adj,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_rmt_logit_adj)

# Test multilevel

ed_rmt_mlogit_adj <- update(ed_rmt_logit_adj, add_nom)

countsummary(ed_rmt_mlogit_adj)

compare_nested(ed_rmt_logit_adj, ed_rmt_mlogit_adj)

AICtab(ed_rmt_mlogit_adj, ed_rmt_mlogit)

#### add adj lag

ed_rmt_mlogit_risk_lag_adj <- update(ed_rmt_mlogit_risk,
            . ~ lag_rmt_adj + .)

countsummary(ed_rmt_mlogit_risk_lag_adj)


### Test multilevel

ed_rmt_logit_risk_lag_adj <- update(ed_rmt_mlogit_risk_lag_adj,
            . ~ . - (1|NOM_ENT))

countsummary(ed_rmt_logit_risk_lag_adj)

compare_nested(ed_rmt_logit_risk_lag_adj, ed_rmt_mlogit_risk_lag_adj)

#### Risk to lag

compare_nested(ed_rmt_mlogit_risk, ed_rmt_mlogit_risk_lag_adj)

#### Lag to risk

compare_nested(ed_rmt_mlogit_adj, ed_rmt_mlogit_risk_lag_adj)

coef_csv(ed_rmt_mlogit_adj)
coef_csv(ed_rmt_mlogit_risk_lag_adj)

## then lag_rmt_comp_cat

# Bivariate model of event dependence

ed_rmt_logit_comp <- glmmTMB(mkbin(remote) ~ lag_rmt_comp_cat,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_rmt_logit_comp)

# Test multilevel

ed_rmt_mlogit_comp <- update(ed_rmt_logit_comp, add_nom)

countsummary(ed_rmt_mlogit_comp)

compare_nested(ed_rmt_logit_comp, ed_rmt_mlogit_comp)

AICtab(ed_rmt_mlogit_comp, ed_rmt_mlogit_adj, ed_rmt_mlogit)

#### add comp lag to risk

ed_rmt_mlogit_risk_lag_comp <- update(ed_rmt_mlogit_risk,
            . ~ lag_rmt_comp_cat + .)

countsummary(ed_rmt_mlogit_risk_lag_comp)


### Test multilevel

ed_rmt_logit_risk_lag_comp <- update(ed_rmt_mlogit_risk_lag_comp,
            . ~ . - (1|NOM_ENT))

countsummary(ed_rmt_logit_risk_lag_comp)

compare_nested(ed_rmt_logit_risk_lag_comp,
                ed_rmt_mlogit_risk_lag_comp)

#### Risk to lag

compare_nested(ed_rmt_mlogit_risk, ed_rmt_mlogit_risk_lag_comp)

#### Lag to risk

compare_nested(ed_rmt_mlogit_comp, ed_rmt_mlogit_risk_lag_comp)

coef_csv(ed_rmt_mlogit_comp)
coef_csv(ed_rmt_mlogit_risk_lag_comp)


### Test VIF

### Calculate VIF of these vars

ed_rmt_logit_risk_lag_glm <- glm(formula(ed_rmt_logit_risk_lag),
                                    data = enve_lag_nm_sem1_nona,
                                    family = "binomial")

summary(ed_rmt_logit_risk_lag_glm)
car::vif(ed_rmt_logit_risk_lag_glm)

ed_rmt_logit_risk_lag_adj_glm <- glm(formula(ed_rmt_logit_risk_lag_adj),
                                    data = enve_lag_nm_sem1_nona,
                                    family = "binomial")

summary(ed_rmt_logit_risk_lag_adj_glm)
car::vif(ed_rmt_logit_risk_lag_glm)

ed_rmt_logit_risk_lag_comp_glm <- glm(formula(ed_rmt_logit_risk_lag_comp),
                                    data = enve_lag_nm_sem1_nona,
                                    family = "binomial")

summary(ed_rmt_logit_risk_lag_comp_glm)
car::vif(ed_rmt_logit_risk_lag_comp_glm)


```


Next, estimate the effect of event dependence on concentration.

Begin with Poisson, (nb may be significant).
Mutilevel not significant
Use ADMB


```{r remote-event-dependence-concentration}

## Use enve_lag_nm_sem1

ed_rmt_tp <- glmmadmb(remote ~ lag_remote,
     data = subset(enve_lag_nm_sem1_nona, remote > 0),
     family = "truncpoiss",
     zeroInflation = FALSE,
     admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE),
     extra.args = "-ndi 60000")

countsummary(ed_rmt_tp)

## Is nb significant?

ed_rmt_tnb <- update(ed_rmt_tp, family = "truncnbinom")

countsummary(ed_rmt_tnb)

compare_nested(ed_rmt_tp, ed_rmt_tnb)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_rmt_mtp <- update(ed_rmt_tp, add_nom)

countsummary(ed_rmt_mtp)

compare_nested(ed_rmt_tp, ed_rmt_mtp)

#negbin
ed_rmt_mtnb <- update(ed_rmt_tnb, add_nom)

countsummary(ed_rmt_mtnb)

compare_nested(ed_rmt_tnb, ed_rmt_mtnb)

compare_nested(ed_rmt_mtp, ed_rmt_mtnb)

### add risk heterogeneity

# compare to risk factors for prevalence

rmt_prv_risk <- update(formula(ed_rmt_mlogit_risk),
                    remote ~ . - (1|NOM_ENT))

ed_rmt_tp_risk_full <- update(ed_rmt_tp, rmt_prv_risk)

countsummary(ed_rmt_tp_risk_full)


# nb

ed_rmt_tnb_risk_full <- update(ed_rmt_tp_risk_full,
                    family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_full)

compare_nested(ed_rmt_tp_risk_full, ed_rmt_tnb_risk_full)

## adding lag to risk model

ed_rmt_tp_risk_lag <- update(ed_rmt_tp_risk_full,
                        . ~ lag_remote + .)

countsummary(ed_rmt_tp_risk_lag)


### nb

ed_rmt_tnb_risk_lag <- update(ed_rmt_tp_risk_lag,
                        family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_lag)

compare_nested(ed_rmt_tp_risk_lag, ed_rmt_tnb_risk_lag)

### multilevel

ed_rmt_mtp_risk_lag <- update(ed_rmt_tp_risk_lag,
                        add_nom)

countsummary(ed_rmt_mtp_risk_lag)

compare_nested(ed_rmt_tp_risk_lag, ed_rmt_mtp_risk_lag)


## significance of risk to lag

compare_nested(ed_rmt_tp, ed_rmt_tp_risk_lag)

## significance of lag to risk

compare_nested(ed_rmt_tp_risk_full, ed_rmt_tp_risk_lag)


## save as csv

coef_csv(ed_rmt_tp)
coef_csv(ed_rmt_tp_risk_lag)
coef_csv(ed_rmt_tp_risk_full)


## repeat for adjusted lag

ed_rmt_tp_adj <- update(ed_rmt_tp, . ~ lag_rmt_adj)

countsummary(ed_rmt_tp_adj)
AICtab(ed_rmt_tp_adj, ed_rmt_tp)

## Is nb significant?

ed_rmt_tnb_adj <- update(ed_rmt_tp_adj, family = "truncnbinom")

countsummary(ed_rmt_tnb_adj)

compare_nested(ed_rmt_tp_adj, ed_rmt_tnb_adj)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_rmt_mtp_adj <- update(ed_rmt_tp_adj, add_nom)

countsummary(ed_rmt_mtp_adj)

compare_nested(ed_rmt_tp_adj, ed_rmt_mtp_adj)



## adding lag to risk model

ed_rmt_tp_risk_lag_adj <- update(ed_rmt_tp_risk_full,
                        . ~ lag_rmt_adj + .)

countsummary(ed_rmt_tp_risk_lag_adj)


### nb

ed_rmt_tnb_risk_lag_adj <- update(ed_rmt_tp_risk_lag_adj,
                        family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_lag_adj)

compare_nested(ed_rmt_tp_risk_lag_adj, ed_rmt_tnb_risk_lag_adj)


### multilevel


ed_rmt_mtp_risk_lag_adj <- update(ed_rmt_tp_risk_lag_adj,
                        add_nom)

countsummary(ed_rmt_mtp_risk_lag_adj)

compare_nested(ed_rmt_tp_risk_lag_adj, ed_rmt_mtp_risk_lag_adj)


## significance of risk to lag

compare_nested(ed_rmt_tp_adj, ed_rmt_tp_risk_lag_adj)

## significance of lag to risk

compare_nested(ed_rmt_tp_risk_full, ed_rmt_tp_risk_lag_adj)

## save as csv

coef_csv(ed_rmt_tp_adj)
coef_csv(ed_rmt_tp_risk_lag_adj)


## repeat for comp lag categories

ed_rmt_tp_comp <- update(ed_rmt_tp, . ~ lag_rmt_comp_cat)

countsummary(ed_rmt_tp_comp)
AICtab(ed_rmt_tp_comp, ed_rmt_tp_adj, ed_rmt_tp)

## Is nb significant?

ed_rmt_tnb_comp <- update(ed_rmt_tp_comp, family = "truncnbinom")

countsummary(ed_rmt_tnb_comp)

compare_nested(ed_rmt_tp_comp, ed_rmt_tnb_comp)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_rmt_mtp_comp <- update(ed_rmt_tp_comp, add_nom)

countsummary(ed_rmt_mtp_comp)

compare_nested(ed_rmt_tp_comp, ed_rmt_mtp_comp)


## adding lag to risk model

ed_rmt_tp_risk_lag_comp <- update(ed_rmt_tp_risk_full,
                        . ~ lag_rmt_comp_cat + .)

countsummary(ed_rmt_tp_risk_lag_comp)

### nb

ed_rmt_tnb_risk_lag_comp <- update(ed_rmt_tp_risk_lag_comp,
                        family = "truncnbinom")

countsummary(ed_rmt_tnb_risk_lag_comp)

compare_nested(ed_rmt_tp_risk_lag_comp, ed_rmt_tnb_risk_lag_comp)


### multilevel

ed_rmt_mtp_risk_lag_comp <- update(ed_rmt_tp_risk_lag_comp,
                        add_nom)

countsummary(ed_rmt_mtp_risk_lag_comp)

compare_nested(ed_rmt_tp_risk_lag_comp, ed_rmt_mtp_risk_lag_comp)

## significance of risk to lag

compare_nested(ed_rmt_tp_comp, ed_rmt_tp_risk_lag_comp)

## significance of lag to risk

compare_nested(ed_rmt_tp_risk_full, ed_rmt_tp_risk_lag_comp)

## save as csv

coef_csv(ed_rmt_tp_comp)
coef_csv(ed_rmt_tp_risk_lag_comp)

```

Next, in person.

#### In person

Repeat for in-person

Prevalence models

```{r inperson-event-dependence-prevalence}


## Use enve_lag_nm_sem1_nona

# Bivariate model of event dependence

ed_inp_logit <- glmmTMB(mkbin(inperson) ~ lag_inperson,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_inp_logit)

# Test multilevel

ed_inp_mlogit <- update(ed_inp_logit, add_nom)

countsummary(ed_inp_mlogit)

compare_nested(ed_inp_logit, ed_inp_mlogit)

### Risk heterogeneity

add_risk_polyb <-  . ~ . +  poly(bribes, 2, raw = TRUE) +
                    yearsquant +
                    subsector_new +
                    size +
                    mylog(bribes_abvic, mean_bribes) +
                    mylog(armas, mean_armas) +
                    mylog(drogas, mean_drogas) +
                    mylog(N, mean_N) +
                    mylog(poblacion, mean_poblacion) +
                    scale(General, mean_General, FALSE) +
                    scale(Derecho, mean_Derecho, FALSE)

ed_inp_mlogit_risk_lag <- update(ed_inp_mlogit, add_risk_polyb)

countsummary(ed_inp_mlogit_risk_lag)

### No lag only risk

ed_inp_mlogit_risk <- update(ed_inp_mlogit_risk_lag, . ~ . - lag_inperson)

countsummary(ed_inp_mlogit_risk)

## test polybribes?

ed_inp_mlogit_risk_b <- update(ed_inp_mlogit_risk,
                . ~ bribes + . - poly(bribes, 2, raw = TRUE))


countsummary(ed_inp_mlogit_risk_b)

compare_nested(ed_inp_mlogit_risk_b, ed_inp_mlogit_risk)


### Test multilevel

ed_inp_logit_risk_lag <- update(ed_inp_mlogit_risk_lag,
            . ~ . - (1|NOM_ENT))

countsummary(ed_inp_logit_risk_lag)

compare_nested(ed_inp_logit_risk_lag, ed_inp_mlogit_risk_lag)

#### Risk to lag

compare_nested(ed_inp_mlogit_risk, ed_inp_mlogit_risk_lag)

#### Lag to risk

compare_nested(ed_inp_mlogit, ed_inp_mlogit_risk_lag)

coef_csv(ed_inp_mlogit)
coef_csv(ed_inp_mlogit_risk)
coef_csv(ed_inp_mlogit_risk_lag)

## Then lag_rmt_adj

# Bivariate model of event dependence

ed_inp_logit_adj <- glmmTMB(mkbin(inperson) ~ lag_inp_adj,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_inp_logit_adj)

# Test multilevel

ed_inp_mlogit_adj <- update(ed_inp_logit_adj, add_nom)

countsummary(ed_inp_mlogit_adj)

compare_nested(ed_inp_logit_adj, ed_inp_mlogit_adj)

AICtab(ed_inp_mlogit_adj, ed_inp_mlogit)

#### add adj lag

ed_inp_mlogit_risk_lag_adj <- update(ed_inp_mlogit_risk,
            . ~ lag_inp_adj + .)

countsummary(ed_inp_mlogit_risk_lag_adj)


### Test multilevel

ed_inp_logit_risk_lag_adj <- update(ed_inp_mlogit_risk_lag_adj,
            . ~ . - (1|NOM_ENT))

countsummary(ed_inp_logit_risk_lag_adj)

compare_nested(ed_inp_logit_risk_lag_adj, ed_inp_mlogit_risk_lag_adj)

#### Risk to lag

compare_nested(ed_inp_mlogit_risk, ed_inp_mlogit_risk_lag_adj)

#### Lag to risk

compare_nested(ed_inp_mlogit_adj, ed_inp_mlogit_risk_lag_adj)

coef_csv(ed_inp_mlogit_adj)
coef_csv(ed_inp_mlogit_risk_lag_adj)

## then lag_inp_comp_cat

# Bivariate model of event dependence

ed_inp_logit_comp <- glmmTMB(mkbin(remote) ~ lag_inp_comp_cat,
                        data = enve_lag_nm_sem1_nona,
                        family = "binomial")

countsummary(ed_inp_logit_comp)

# Test multilevel

ed_inp_mlogit_comp <- update(ed_inp_logit_comp, add_nom)

countsummary(ed_inp_mlogit_comp)

compare_nested(ed_inp_logit_comp, ed_inp_mlogit_comp)

AICtab(ed_inp_mlogit_comp, ed_inp_mlogit_adj, ed_inp_mlogit)

#### add comp lag to risk

ed_inp_mlogit_risk_lag_comp <- update(ed_inp_mlogit_risk,
            . ~ lag_inp_comp_cat + .)

countsummary(ed_inp_mlogit_risk_lag_comp)


### Test multilevel

ed_inp_logit_risk_lag_comp <- update(ed_inp_mlogit_risk_lag_comp,
            . ~ . - (1|NOM_ENT))

countsummary(ed_inp_logit_risk_lag_comp)

compare_nested(ed_inp_logit_risk_lag_comp,
                ed_inp_mlogit_risk_lag_comp)


#### Risk to lag

compare_nested(ed_inp_mlogit_risk, ed_inp_mlogit_risk_lag_comp)

#### Lag to risk

compare_nested(ed_inp_mlogit_comp, ed_inp_mlogit_risk_lag_comp)

coef_csv(ed_inp_mlogit_comp)
coef_csv(ed_inp_mlogit_risk_lag_comp)


# VIF for these


ed_inp_logit_risk_lag_glm <- glm(formula(ed_inp_logit_risk_lag),
                                    data = enve_lag_nm_sem1_nona,
                                    family = "binomial")

summary(ed_inp_logit_risk_lag_glm)
car::vif(ed_inp_logit_risk_lag_glm)

ed_inp_logit_risk_lag_adj_glm <- glm(formula(ed_inp_logit_risk_lag_adj),
                                    data = enve_lag_nm_sem1_nona,
                                    family = "binomial")

summary(ed_inp_logit_risk_lag_adj_glm)
car::vif(ed_inp_logit_risk_lag_glm)

ed_inp_logit_risk_lag_comp_glm <- glm(formula(ed_inp_logit_risk_lag_comp),
                                    data = enve_lag_nm_sem1_nona,
                                    family = "binomial")

summary(ed_inp_logit_risk_lag_comp_glm)
car::vif(ed_inp_logit_risk_lag_comp_glm)


```


Next, estimate the effect of event dependence in the truncated count.

```{r inperson-event-dependence-concentration}


## Use enve_lag_nm_sem1

ed_inp_tp <- glmmadmb(inperson ~ lag_inperson,
     data = subset(enve_lag_nm_sem1_nona, inperson > 0),
     family = "truncpoiss",
     zeroInflation = FALSE,
     admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE),
     extra.args = "-ndi 60000")

countsummary(ed_inp_tp)

## Is nb significant?

ed_inp_tnb <- update(ed_inp_tp, family = "truncnbinom")

countsummary(ed_inp_tnb)

compare_nested(ed_inp_tp, ed_inp_tnb)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_inp_mtp <- update(ed_inp_tp, add_nom)

countsummary(ed_inp_mtp)

compare_nested(ed_inp_tp, ed_inp_mtp)

### add risk heterogeneity

# compare to risk factors for prevalence

inp_prv_risk <- update(formula(ed_inp_mlogit_risk),
                    inperson ~ . - (1|NOM_ENT))

ed_inp_tp_risk <- update(ed_inp_tp, inp_prv_risk)

countsummary(ed_inp_tp_risk)


ed_inp_tp_best_risk <- ed_inp_tp_risk

## adding lag to risk model
ed_inp_tp_risk_lag <- update(ed_inp_tp_best_risk,
                        . ~ lag_inperson + .)

countsummary(ed_inp_tp_risk_lag)

## significance of risk to lag

compare_nested(ed_inp_tp, ed_inp_tp_risk_lag)

## significance of lag to risk

compare_nested(ed_inp_tp_best_risk, ed_inp_tp_risk_lag)

## save as csv

coef_csv(ed_inp_tp)
coef_csv(ed_inp_tp_risk_lag)
coef_csv(ed_inp_tp_best_risk)

## repeat for adjusted lag

ed_inp_tp_adj <- glmmadmb(inperson ~ lag_inp_adj,
     data = subset(enve_lag_nm_sem1_nona, inperson > 0),
     family = "truncpoiss",
     zeroInflation = FALSE,
     admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE),
     extra.args = "-ndi 60000")

countsummary(ed_inp_tp_adj)

## Is nb significant?

ed_inp_tnb_adj <- update(ed_inp_tp_adj, family = "truncnbinom")

countsummary(ed_inp_tnb_adj)

compare_nested(ed_inp_tp_adj, ed_inp_tnb_adj)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_inp_mtp_adj <- update(ed_inp_tp_adj, add_nom)

countsummary(ed_inp_mtp_adj)

compare_nested(ed_inp_tp_adj, ed_inp_mtp_adj)


### add risk heterogeneity: previous indicate only ROL might be significant. Use the risk factors for prevalence to compare

## adding lag to risk model
ed_inp_tp_risk_lag_adj <- update(ed_inp_tp_best_risk,
                        . ~ lag_inp_adj + .)

countsummary(ed_inp_tp_risk_lag_adj)

## significance of risk to lag

compare_nested(ed_inp_tp_adj, ed_inp_tp_risk_lag_adj)

## significance of lag to risk

compare_nested(ed_inp_tp_best_risk, ed_inp_tp_risk_lag_adj)

## save as csv

coef_csv(ed_inp_tp_adj)
coef_csv(ed_inp_tp_risk_lag_adj)


## repeat for comp lag categories

ed_inp_tp_comp <- glmmadmb(inperson ~ lag_inp_comp_cat,
     data = subset(enve_lag_nm_sem1_nona, inperson > 0),
     family = "truncpoiss",
     zeroInflation = FALSE,
     admb.opts = glmmADMB::admbControl(noinit = FALSE, shess=FALSE),
     extra.args = "-ndi 60000")

countsummary(ed_inp_tp_comp)

## Is nb significant?

ed_inp_tnb_comp <- update(ed_inp_tp_comp, family = "truncnbinom")

countsummary(ed_inp_tnb_comp)

compare_nested(ed_inp_tp_comp, ed_inp_tnb_comp)

## Is multilevel significant? (previous results suggest it is not)
# poisson
ed_inp_mtp_comp <- update(ed_inp_tp_comp, add_nom)

countsummary(ed_inp_mtp_comp)

compare_nested(ed_inp_tp_comp, ed_inp_mtp_comp)


### add risk heterogeneity: previous indicate only ROL might be significant. Use the risk factors for prevalence to compare

## adding lag to risk model
ed_inp_tp_risk_lag_comp <- update(ed_inp_tp_best_risk,
                        . ~ lag_inp_comp_cat + .)

countsummary(ed_inp_tp_risk_lag_comp)

## significance of risk to lag

compare_nested(ed_inp_tp_comp, ed_inp_tp_risk_lag_comp)

## significance of lag to risk

compare_nested(ed_inp_tp_best_risk, ed_inp_tp_risk_lag_comp)

## save as csv

coef_csv(ed_inp_tp_comp)
coef_csv(ed_inp_tp_risk_lag_comp)

```


# Benchmark stats

```{r timing, cache=FALSE}
endtime <- proc.time()
time <- endtime - starttime
time

print(paste("the script took", round(time[3]/60,2),
              "minutes to run.", sep=" "))
```

# References
